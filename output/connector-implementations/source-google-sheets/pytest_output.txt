============================= test session starts ==============================
platform darwin -- Python 3.13.7, pytest-9.0.1, pluggy-1.6.0 -- /Users/amaannawab/research/connector-platform/connector-generator/output/connector-implementations/source-google-sheets/venv/bin/python
cachedir: .pytest_cache
rootdir: /Users/amaannawab/research/connector-platform/connector-generator/output/connector-implementations/source-google-sheets/tests
configfile: pytest.ini
plugins: cov-7.0.0
collecting ... collected 16 items / 4 errors

==================================== ERRORS ====================================
_______________________ ERROR collecting test_config.py ________________________

    """
    Test configuration validation for Google Sheets connector.
    
    Tests:
    - Valid configuration parsing
    - Missing required fields
    - Invalid field types
    - Authentication type detection
    - Pydantic discriminator handling
    """
    
    import sys
    import os
    import pytest
    from pydantic import ValidationError
    
    # Add src to path
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))
    
>   from config import (
        GoogleSheetsConfig,
        ServiceAccountCredentials,
        OAuth2Credentials,
        AuthType,
        StreamSelection,
    )

tests/test_config.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Configuration models for Google Sheets connector using Pydantic.
    
    Provides validation and type safety for connector configuration.
    """
    
    import json
    import re
    from enum import Enum
    from typing import Any, Dict, List, Optional, Union
    
    from pydantic import BaseModel, Field, field_validator, model_validator
    
    
    class AuthType(str, Enum):
        """Supported authentication types."""
    
        SERVICE_ACCOUNT = "service_account"
        OAUTH2 = "oauth2"
    
    
    class ServiceAccountCredentials(BaseModel):
        """Configuration for Service Account authentication."""
    
        auth_type: AuthType = Field(
            default=AuthType.SERVICE_ACCOUNT,
            description="Authentication type identifier",
        )
        service_account_info: Optional[Union[str, Dict[str, Any]]] = Field(
            default=None,
            description="Service account JSON key as string or dictionary",
        )
        service_account_file: Optional[str] = Field(
            default=None,
            description="Path to service account JSON key file",
        )
    
        @model_validator(mode="after")
        def validate_credentials_source(self) -> "ServiceAccountCredentials":
            """Ensure at least one credential source is provided."""
            if not self.service_account_info and not self.service_account_file:
                raise ValueError(
                    "Must provide either service_account_info or service_account_file"
                )
            return self
    
        @field_validator("service_account_info", mode="before")
        @classmethod
        def parse_service_account_info(cls, v: Optional[Union[str, Dict]]) -> Optional[Dict]:
            """Parse service account info from string if needed."""
            if v is None:
                return None
            if isinstance(v, str):
                try:
                    return json.loads(v)
                except json.JSONDecodeError as e:
                    raise ValueError(f"Invalid JSON in service_account_info: {e}")
            return v
    
    
    class OAuth2Credentials(BaseModel):
        """Configuration for OAuth2 authentication."""
    
        auth_type: AuthType = Field(
            default=AuthType.OAUTH2,
            description="Authentication type identifier",
        )
        client_id: str = Field(
            ...,
            min_length=1,
            description="OAuth2 client ID",
        )
        client_secret: str = Field(
            ...,
            min_length=1,
            description="OAuth2 client secret",
        )
        refresh_token: str = Field(
            ...,
            min_length=1,
            description="OAuth2 refresh token",
        )
        access_token: Optional[str] = Field(
            default=None,
            description="Optional existing access token",
        )
    
    
    # Union type for credentials
    CredentialsConfig = Union[ServiceAccountCredentials, OAuth2Credentials]
    
    
    class StreamSelection(BaseModel):
        """Configuration for selecting which streams/sheets to sync."""
    
        sheet_names: Optional[List[str]] = Field(
            default=None,
            description="List of sheet names to sync. If None, all sheets are synced.",
        )
        exclude_sheets: Optional[List[str]] = Field(
            default=None,
            description="List of sheet names to exclude from sync.",
        )
    
    
>   class GoogleSheetsConfig(BaseModel):

src/config.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

mcs = <class 'pydantic._internal._model_construction.ModelMetaclass'>
cls_name = 'GoogleSheetsConfig', bases = (<class 'pydantic.main.BaseModel'>,)
namespace = {'__module__': 'config', '__qualname__': 'GoogleSheetsConfig', '__firstlineno__': 106, '__annotations__': {'spreadshee...t 0x103e998a0>, '__static_attributes__': (), 'model_config': {}, '__class_vars__': set(), '__private_attributes__': {}}
__pydantic_generic_metadata__ = None, __pydantic_reset_parent_namespace__ = True
_create_model_module = None, kwargs = {}
raw_annotations = {'credentials': typing.Union[config.ServiceAccountCredentials, config.OAuth2Credentials], 'date_time_render_option': <class 'str'>, 'include_row_number': <class 'bool'>, 'requests_per_minute': <class 'int'>, ...}
base_field_names = set(), class_vars = set()

    def __new__(
        mcs,
        cls_name: str,
        bases: tuple[type[Any], ...],
        namespace: dict[str, Any],
        __pydantic_generic_metadata__: PydanticGenericMetadata | None = None,
        __pydantic_reset_parent_namespace__: bool = True,
        _create_model_module: str | None = None,
        **kwargs: Any,
    ) -> type:
        """Metaclass for creating Pydantic models.
    
        Args:
            cls_name: The name of the class to be created.
            bases: The base classes of the class to be created.
            namespace: The attribute dictionary of the class to be created.
            __pydantic_generic_metadata__: Metadata for generic models.
            __pydantic_reset_parent_namespace__: Reset parent namespace.
            _create_model_module: The module of the class to be created, if created by `create_model`.
            **kwargs: Catch-all for any other keyword arguments.
    
        Returns:
            The new class created by the metaclass.
        """
        # Note `ModelMetaclass` refers to `BaseModel`, but is also used to *create* `BaseModel`, so we rely on the fact
        # that `BaseModel` itself won't have any bases, but any subclass of it will, to determine whether the `__new__`
        # call we're in the middle of is for the `BaseModel` class.
        if bases:
            raw_annotations: dict[str, Any]
            if sys.version_info >= (3, 14):
                if (
                    '__annotations__' in namespace
                ):  # `from __future__ import annotations` was used in the model's module
                    raw_annotations = namespace['__annotations__']
                else:
                    # See https://docs.python.org/3.14/library/annotationlib.html#using-annotations-in-a-metaclass:
                    from annotationlib import Format, call_annotate_function, get_annotate_from_class_namespace
    
                    if annotate := get_annotate_from_class_namespace(namespace):
                        raw_annotations = call_annotate_function(annotate, format=Format.FORWARDREF)
                    else:
                        raw_annotations = {}
            else:
                raw_annotations = namespace.get('__annotations__', {})
    
            base_field_names, class_vars, base_private_attributes = mcs._collect_bases_data(bases)
    
            config_wrapper = ConfigWrapper.for_model(bases, namespace, raw_annotations, kwargs)
            namespace['model_config'] = config_wrapper.config_dict
            private_attributes = inspect_namespace(
                namespace, raw_annotations, config_wrapper.ignored_types, class_vars, base_field_names
            )
            if private_attributes or base_private_attributes:
                original_model_post_init = get_model_post_init(namespace, bases)
                if original_model_post_init is not None:
                    # if there are private_attributes and a model_post_init function, we handle both
    
                    @wraps(original_model_post_init)
                    def wrapped_model_post_init(self: BaseModel, context: Any, /) -> None:
                        """We need to both initialize private attributes and call the user-defined model_post_init
                        method.
                        """
                        init_private_attributes(self, context)
                        original_model_post_init(self, context)
    
                    namespace['model_post_init'] = wrapped_model_post_init
                else:
                    namespace['model_post_init'] = init_private_attributes
    
            namespace['__class_vars__'] = class_vars
            namespace['__private_attributes__'] = {**base_private_attributes, **private_attributes}
    
            cls = cast('type[BaseModel]', super().__new__(mcs, cls_name, bases, namespace, **kwargs))
            BaseModel_ = import_cached_base_model()
    
            mro = cls.__mro__
            if Generic in mro and mro.index(Generic) < mro.index(BaseModel_):
                warnings.warn(
                    GenericBeforeBaseModelWarning(
                        'Classes should inherit from `BaseModel` before generic classes (e.g. `typing.Generic[T]`) '
                        'for pydantic generics to work properly.'
                    ),
                    stacklevel=2,
                )
    
            cls.__pydantic_custom_init__ = not getattr(cls.__init__, '__pydantic_base_init__', False)
            cls.__pydantic_post_init__ = (
                None if cls.model_post_init is BaseModel_.model_post_init else 'model_post_init'
            )
    
            cls.__pydantic_setattr_handlers__ = {}
    
            cls.__pydantic_decorators__ = DecoratorInfos.build(cls)
            cls.__pydantic_decorators__.update_from_config(config_wrapper)
    
            # Use the getattr below to grab the __parameters__ from the `typing.Generic` parent class
            if __pydantic_generic_metadata__:
                cls.__pydantic_generic_metadata__ = __pydantic_generic_metadata__
            else:
                parent_parameters = getattr(cls, '__pydantic_generic_metadata__', {}).get('parameters', ())
                parameters = getattr(cls, '__parameters__', None) or parent_parameters
                if parameters and parent_parameters and not all(x in parameters for x in parent_parameters):
                    from ..root_model import RootModelRootType
    
                    missing_parameters = tuple(x for x in parameters if x not in parent_parameters)
                    if RootModelRootType in parent_parameters and RootModelRootType not in parameters:
                        # This is a special case where the user has subclassed `RootModel`, but has not parametrized
                        # RootModel with the generic type identifiers being used. Ex:
                        # class MyModel(RootModel, Generic[T]):
                        #    root: T
                        # Should instead just be:
                        # class MyModel(RootModel[T]):
                        #   root: T
                        parameters_str = ', '.join([x.__name__ for x in missing_parameters])
                        error_message = (
                            f'{cls.__name__} is a subclass of `RootModel`, but does not include the generic type identifier(s) '
                            f'{parameters_str} in its parameters. '
                            f'You should parametrize RootModel directly, e.g., `class {cls.__name__}(RootModel[{parameters_str}]): ...`.'
                        )
                    else:
                        combined_parameters = parent_parameters + missing_parameters
                        parameters_str = ', '.join([str(x) for x in combined_parameters])
                        generic_type_label = f'typing.Generic[{parameters_str}]'
                        error_message = (
                            f'All parameters must be present on typing.Generic;'
                            f' you should inherit from {generic_type_label}.'
                        )
                        if Generic not in bases:  # pragma: no cover
                            # We raise an error here not because it is desirable, but because some cases are mishandled.
                            # It would be nice to remove this error and still have things behave as expected, it's just
                            # challenging because we are using a custom `__class_getitem__` to parametrize generic models,
                            # and not returning a typing._GenericAlias from it.
                            bases_str = ', '.join([x.__name__ for x in bases] + [generic_type_label])
                            error_message += (
                                f' Note: `typing.Generic` must go last: `class {cls.__name__}({bases_str}): ...`)'
                            )
                    raise TypeError(error_message)
    
                cls.__pydantic_generic_metadata__ = {
                    'origin': None,
                    'args': (),
                    'parameters': parameters,
                }
    
            cls.__pydantic_complete__ = False  # Ensure this specific class gets completed
    
            # preserve `__set_name__` protocol defined in https://peps.python.org/pep-0487
            # for attributes not in `new_namespace` (e.g. private attributes)
            for name, obj in private_attributes.items():
                obj.__set_name__(cls, name)
    
            if __pydantic_reset_parent_namespace__:
                cls.__pydantic_parent_namespace__ = build_lenient_weakvaluedict(parent_frame_namespace())
            parent_namespace: dict[str, Any] | None = getattr(cls, '__pydantic_parent_namespace__', None)
            if isinstance(parent_namespace, dict):
                parent_namespace = unpack_lenient_weakvaluedict(parent_namespace)
    
            ns_resolver = NsResolver(parent_namespace=parent_namespace)
    
            set_model_fields(cls, config_wrapper=config_wrapper, ns_resolver=ns_resolver)
    
            # This is also set in `complete_model_class()`, after schema gen because they are recreated.
            # We set them here as well for backwards compatibility:
            cls.__pydantic_computed_fields__ = {
                k: v.info for k, v in cls.__pydantic_decorators__.computed_fields.items()
            }
    
            if config_wrapper.defer_build:
                set_model_mocks(cls)
            else:
                # Any operation that requires accessing the field infos instances should be put inside
                # `complete_model_class()`:
>               complete_model_class(
                    cls,
                    config_wrapper,
                    ns_resolver,
                    raise_errors=False,
                    create_model_module=_create_model_module,
                )

venv/lib/python3.13/site-packages/pydantic/_internal/_model_construction.py:255: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'config.GoogleSheetsConfig'>, config_wrapper = ConfigWrapper()
ns_resolver = <pydantic._internal._namespace_utils.NsResolver object at 0x103e363f0>

    def complete_model_class(
        cls: type[BaseModel],
        config_wrapper: ConfigWrapper,
        ns_resolver: NsResolver,
        *,
        raise_errors: bool = True,
        call_on_complete_hook: bool = True,
        create_model_module: str | None = None,
    ) -> bool:
        """Finish building a model class.
    
        This logic must be called after class has been created since validation functions must be bound
        and `get_type_hints` requires a class object.
    
        Args:
            cls: BaseModel or dataclass.
            config_wrapper: The config wrapper instance.
            ns_resolver: The namespace resolver instance to use during schema building.
            raise_errors: Whether to raise errors.
            call_on_complete_hook: Whether to call the `__pydantic_on_complete__` hook.
            create_model_module: The module of the class to be created, if created by `create_model`.
    
        Returns:
            `True` if the model is successfully completed, else `False`.
    
        Raises:
            PydanticUndefinedAnnotation: If `PydanticUndefinedAnnotation` occurs in`__get_pydantic_core_schema__`
                and `raise_errors=True`.
        """
        typevars_map = get_model_typevars_map(cls)
    
        if not cls.__pydantic_fields_complete__:
            # Note: when coming from `ModelMetaclass.__new__()`, this results in fields being built twice.
            # We do so a second time here so that we can get the `NameError` for the specific undefined annotation.
            # Alternatively, we could let `GenerateSchema()` raise the error, but there are cases where incomplete
            # fields are inherited in `collect_model_fields()` and can actually have their annotation resolved in the
            # generate schema process. As we want to avoid having `__pydantic_fields_complete__` set to `False`
            # when `__pydantic_complete__` is `True`, we rebuild here:
            try:
                cls.__pydantic_fields__ = rebuild_model_fields(
                    cls,
                    config_wrapper=config_wrapper,
                    ns_resolver=ns_resolver,
                    typevars_map=typevars_map,
                )
            except NameError as e:
                exc = PydanticUndefinedAnnotation.from_name_error(e)
                set_model_mocks(cls, f'`{exc.name}`')
                if raise_errors:
                    raise exc from e
    
            if not raise_errors and not cls.__pydantic_fields_complete__:
                # No need to continue with schema gen, it is guaranteed to fail
                return False
    
            assert cls.__pydantic_fields_complete__
    
        gen_schema = GenerateSchema(
            config_wrapper,
            ns_resolver,
            typevars_map,
        )
    
        try:
>           schema = gen_schema.generate_schema(cls)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_model_construction.py:648: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x103e6e570>
obj = <class 'config.GoogleSheetsConfig'>

    def generate_schema(
        self,
        obj: Any,
    ) -> core_schema.CoreSchema:
        """Generate core schema.
    
        Args:
            obj: The object to generate core schema for.
    
        Returns:
            The generated core schema.
    
        Raises:
            PydanticUndefinedAnnotation:
                If it is not possible to evaluate forward reference.
            PydanticSchemaGenerationError:
                If it is not possible to generate pydantic-core schema.
            TypeError:
                - If `alias_generator` returns a disallowed type (must be str, AliasPath or AliasChoices).
                - If V1 style validator with `each_item=True` applied on a wrong field.
            PydanticUserError:
                - If `typing.TypedDict` is used instead of `typing_extensions.TypedDict` on Python < 3.12.
                - If `__modify_schema__` method is used instead of `__get_pydantic_json_schema__`.
        """
        schema = self._generate_schema_from_get_schema_method(obj, obj)
    
        if schema is None:
>           schema = self._generate_schema_inner(obj)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x103e6e570>
obj = <class 'config.GoogleSheetsConfig'>

    def _generate_schema_inner(self, obj: Any) -> core_schema.CoreSchema:
        if typing_objects.is_self(obj):
            obj = self._resolve_self_type(obj)
    
        if typing_objects.is_annotated(get_origin(obj)):
            return self._annotated_schema(obj)
    
        if isinstance(obj, dict):
            # we assume this is already a valid schema
            return obj  # type: ignore[return-value]
    
        if isinstance(obj, str):
            obj = ForwardRef(obj)
    
        if isinstance(obj, ForwardRef):
            return self.generate_schema(self._resolve_forward_ref(obj))
    
        BaseModel = import_cached_base_model()
    
        if lenient_issubclass(obj, BaseModel):
            with self.model_type_stack.push(obj):
>               return self._model_schema(obj)
                       ^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1023: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x103e6e570>
cls = <class 'config.GoogleSheetsConfig'>

    def _model_schema(self, cls: type[BaseModel]) -> core_schema.CoreSchema:
        """Generate schema for a Pydantic model."""
        BaseModel_ = import_cached_base_model()
    
        with self.defs.get_schema_or_ref(cls) as (model_ref, maybe_schema):
            if maybe_schema is not None:
                return maybe_schema
    
            schema = cls.__dict__.get('__pydantic_core_schema__')
            if schema is not None and not isinstance(schema, MockCoreSchema):
                if schema['type'] == 'definitions':
                    schema = self.defs.unpack_definitions(schema)
                ref = get_ref(schema)
                if ref:
                    return self.defs.create_definition_reference_schema(schema)
                else:
                    return schema
    
            config_wrapper = ConfigWrapper(cls.model_config, check=False)
    
            with self._config_wrapper_stack.push(config_wrapper), self._ns_resolver.push(cls):
                core_config = self._config_wrapper.core_config(title=cls.__name__)
    
                if cls.__pydantic_fields_complete__ or cls is BaseModel_:
                    fields = getattr(cls, '__pydantic_fields__', {})
                else:
                    if '__pydantic_fields__' not in cls.__dict__:
                        # This happens when we have a loop in the schema generation:
                        # class Base[T](BaseModel):
                        #     t: T
                        #
                        # class Other(BaseModel):
                        #     b: 'Base[Other]'
                        # When we build fields for `Other`, we evaluate the forward annotation.
                        # At this point, `Other` doesn't have the model fields set. We create
                        # `Base[Other]`; model fields are successfully built, and we try to generate
                        # a schema for `t: Other`. As `Other.__pydantic_fields__` aren't set, we abort.
                        raise PydanticUndefinedAnnotation(
                            name=cls.__name__,
                            message=f'Class {cls.__name__!r} is not defined',
                        )
                    try:
                        fields = rebuild_model_fields(
                            cls,
                            config_wrapper=self._config_wrapper,
                            ns_resolver=self._ns_resolver,
                            typevars_map=self._typevars_map or {},
                        )
                    except NameError as e:
                        raise PydanticUndefinedAnnotation.from_name_error(e) from e
    
                decorators = cls.__pydantic_decorators__
                computed_fields = decorators.computed_fields
                check_decorator_fields_exist(
                    chain(
                        decorators.field_validators.values(),
                        decorators.field_serializers.values(),
                        decorators.validators.values(),
                    ),
                    {*fields.keys(), *computed_fields.keys()},
                )
    
                model_validators = decorators.model_validators.values()
    
                extras_schema = None
                extras_keys_schema = None
                if core_config.get('extra_fields_behavior') == 'allow':
                    assert cls.__mro__[0] is cls
                    assert cls.__mro__[-1] is object
                    for candidate_cls in cls.__mro__[:-1]:
                        extras_annotation = getattr(candidate_cls, '__annotations__', {}).get(
                            '__pydantic_extra__', None
                        )
                        if extras_annotation is not None:
                            if isinstance(extras_annotation, str):
                                extras_annotation = _typing_extra.eval_type_backport(
                                    _typing_extra._make_forward_ref(
                                        extras_annotation, is_argument=False, is_class=True
                                    ),
                                    *self._types_namespace,
                                )
                            tp = get_origin(extras_annotation)
                            if tp not in DICT_TYPES:
                                raise PydanticSchemaGenerationError(
                                    'The type annotation for `__pydantic_extra__` must be `dict[str, ...]`'
                                )
                            extra_keys_type, extra_items_type = self._get_args_resolving_forward_refs(
                                extras_annotation,
                                required=True,
                            )
                            if extra_keys_type is not str:
                                extras_keys_schema = self.generate_schema(extra_keys_type)
                            if not typing_objects.is_any(extra_items_type):
                                extras_schema = self.generate_schema(extra_items_type)
                            if extras_keys_schema is not None or extras_schema is not None:
                                break
    
                generic_origin: type[BaseModel] | None = getattr(cls, '__pydantic_generic_metadata__', {}).get('origin')
    
                if cls.__pydantic_root_model__:
                    # FIXME: should the common field metadata be used here?
                    inner_schema, _ = self._common_field_schema('root', fields['root'], decorators)
                    inner_schema = apply_model_validators(inner_schema, model_validators, 'inner')
                    model_schema = core_schema.model_schema(
                        cls,
                        inner_schema,
                        generic_origin=generic_origin,
                        custom_init=getattr(cls, '__pydantic_custom_init__', None),
                        root_model=True,
                        post_init=getattr(cls, '__pydantic_post_init__', None),
                        config=core_config,
                        ref=model_ref,
                    )
                else:
                    fields_schema: core_schema.CoreSchema = core_schema.model_fields_schema(
>                       {k: self._generate_md_field_schema(k, v, decorators) for k, v in fields.items()},
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                        computed_fields=[
                            self._computed_field_schema(d, decorators.field_serializers)
                            for d in computed_fields.values()
                        ],
                        extras_schema=extras_schema,
                        extras_keys_schema=extras_keys_schema,
                        model_name=cls.__name__,
                    )

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:856: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x103e6e570>
name = 'credentials'
field_info = FieldInfo(annotation=Union[ServiceAccountCredentials, OAuth2Credentials], required=True, description='Authentication credentials', discriminator='auth_type')
decorators = DecoratorInfos(validators={}, field_validators={'extract_spreadsheet_id': Decorator(cls_ref='config.GoogleSheetsConfig...cUndefined))}, root_validators={}, field_serializers={}, model_serializers={}, model_validators={}, computed_fields={})

    def _generate_md_field_schema(
        self,
        name: str,
        field_info: FieldInfo,
        decorators: DecoratorInfos,
    ) -> core_schema.ModelField:
        """Prepare a ModelField to represent a model field."""
>       schema, metadata = self._common_field_schema(name, field_info, decorators)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x103e6e570>
name = 'credentials'
field_info = FieldInfo(annotation=Union[ServiceAccountCredentials, OAuth2Credentials], required=True, description='Authentication credentials', discriminator='auth_type')
decorators = DecoratorInfos(validators={}, field_validators={'extract_spreadsheet_id': Decorator(cls_ref='config.GoogleSheetsConfig...cUndefined))}, root_validators={}, field_serializers={}, model_serializers={}, model_validators={}, computed_fields={})

    def _common_field_schema(  # C901
        self, name: str, field_info: FieldInfo, decorators: DecoratorInfos
    ) -> tuple[CoreSchema, dict[str, Any]]:
        source_type, annotations = field_info.annotation, field_info.metadata
    
        def set_discriminator(schema: CoreSchema) -> CoreSchema:
            schema = self._apply_discriminator_to_union(schema, field_info.discriminator)
            return schema
    
        # Convert `@field_validator` decorators to `Before/After/Plain/WrapValidator` instances:
        validators_from_decorators = [
            _mode_to_validator[decorator.info.mode]._from_decorator(decorator)
            for decorator in filter_field_decorator_info_by_field(decorators.field_validators.values(), name)
        ]
    
        with self.field_name_stack.push(name):
            if field_info.discriminator is not None:
>               schema = self._apply_annotations(
                    source_type, annotations + validators_from_decorators, transform_inner_schema=set_discriminator
                )

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1278: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x103e6e570>
source_type = typing.Union[config.ServiceAccountCredentials, config.OAuth2Credentials]
annotations = []
transform_inner_schema = <function GenerateSchema._common_field_schema.<locals>.set_discriminator at 0x103e99940>
check_unsupported_field_info_attributes = True

    def _apply_annotations(
        self,
        source_type: Any,
        annotations: list[Any],
        transform_inner_schema: Callable[[CoreSchema], CoreSchema] = lambda x: x,
        check_unsupported_field_info_attributes: bool = True,
    ) -> CoreSchema:
        """Apply arguments from `Annotated` or from `FieldInfo` to a schema.
    
        This gets called by `GenerateSchema._annotated_schema` but differs from it in that it does
        not expect `source_type` to be an `Annotated` object, it expects it to be  the first argument of that
        (in other words, `GenerateSchema._annotated_schema` just unpacks `Annotated`, this process it).
        """
        annotations = list(_known_annotated_metadata.expand_grouped_metadata(annotations))
    
        pydantic_js_annotation_functions: list[GetJsonSchemaFunction] = []
    
        def inner_handler(obj: Any) -> CoreSchema:
            schema = self._generate_schema_from_get_schema_method(obj, source_type)
    
            if schema is None:
                schema = self._generate_schema_inner(obj)
    
            metadata_js_function = _extract_get_pydantic_json_schema(obj)
            if metadata_js_function is not None:
                metadata_schema = resolve_original_schema(schema, self.defs)
                if metadata_schema is not None:
                    self._add_js_function(metadata_schema, metadata_js_function)
            return transform_inner_schema(schema)
    
        get_inner_schema = CallbackGetCoreSchemaHandler(inner_handler, self)
    
        for annotation in annotations:
            if annotation is None:
                continue
            get_inner_schema = self._get_wrapped_inner_schema(
                get_inner_schema,
                annotation,
                pydantic_js_annotation_functions,
                check_unsupported_field_info_attributes=check_unsupported_field_info_attributes,
            )
    
>       schema = get_inner_schema(source_type)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2227: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._schema_generation_shared.CallbackGetCoreSchemaHandler object at 0x103bde0a0>
source_type = typing.Union[config.ServiceAccountCredentials, config.OAuth2Credentials]

    def __call__(self, source_type: Any, /) -> core_schema.CoreSchema:
>       schema = self._handler(source_type)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_schema_generation_shared.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = typing.Union[config.ServiceAccountCredentials, config.OAuth2Credentials]

    def inner_handler(obj: Any) -> CoreSchema:
        schema = self._generate_schema_from_get_schema_method(obj, source_type)
    
        if schema is None:
            schema = self._generate_schema_inner(obj)
    
        metadata_js_function = _extract_get_pydantic_json_schema(obj)
        if metadata_js_function is not None:
            metadata_schema = resolve_original_schema(schema, self.defs)
            if metadata_schema is not None:
                self._add_js_function(metadata_schema, metadata_js_function)
>       return transform_inner_schema(schema)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2213: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

schema = {'choices': [{'schema_ref': 'config.ServiceAccountCredentials:4361121312', 'type': 'definition-ref'}, {'schema_ref': 'config.OAuth2Credentials:4965600480', 'type': 'definition-ref'}], 'type': 'union'}

    def set_discriminator(schema: CoreSchema) -> CoreSchema:
>       schema = self._apply_discriminator_to_union(schema, field_info.discriminator)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x103e6e570>
schema = {'choices': [{'schema_ref': 'config.ServiceAccountCredentials:4361121312', 'type': 'definition-ref'}, {'schema_ref': 'config.OAuth2Credentials:4965600480', 'type': 'definition-ref'}], 'type': 'union'}
discriminator = 'auth_type'

    def _apply_discriminator_to_union(
        self, schema: CoreSchema, discriminator: str | Discriminator | None
    ) -> CoreSchema:
        if discriminator is None:
            return schema
        try:
>           return _discriminated_union.apply_discriminator(
                schema,
                discriminator,
                self.defs._definitions,
            )

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:675: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

schema = {'choices': [{'schema_ref': 'config.ServiceAccountCredentials:4361121312', 'type': 'definition-ref'}, {'schema_ref': 'config.OAuth2Credentials:4965600480', 'type': 'definition-ref'}], 'type': 'union'}
discriminator = 'auth_type'
definitions = {'config.OAuth2Credentials:4965600480': {'cls': <class 'config.OAuth2Credentials'>, 'config': {'title': 'OAuth2Credent...Credentials'>, 'config': {'title': 'ServiceAccountCredentials'}, 'custom_init': False, 'root_model': False, ...}, ...}}

    def apply_discriminator(
        schema: core_schema.CoreSchema,
        discriminator: str | Discriminator,
        definitions: dict[str, core_schema.CoreSchema] | None = None,
    ) -> core_schema.CoreSchema:
        """Applies the discriminator and returns a new core schema.
    
        Args:
            schema: The input schema.
            discriminator: The name of the field which will serve as the discriminator.
            definitions: A mapping of schema ref to schema.
    
        Returns:
            The new core schema.
    
        Raises:
            TypeError:
                - If `discriminator` is used with invalid union variant.
                - If `discriminator` is used with `Union` type with one variant.
                - If `discriminator` value mapped to multiple choices.
            MissingDefinitionForUnionRef:
                If the definition for ref is missing.
            PydanticUserError:
                - If a model in union doesn't have a discriminator field.
                - If discriminator field has a non-string alias.
                - If discriminator fields have different aliases.
                - If discriminator field not of type `Literal`.
        """
        from ..types import Discriminator
    
        if isinstance(discriminator, Discriminator):
            if isinstance(discriminator.discriminator, str):
                discriminator = discriminator.discriminator
            else:
                return discriminator._convert_schema(schema)
    
>       return _ApplyInferredDiscriminator(discriminator, definitions or {}).apply(schema)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x103e5c590>
schema = {'choices': [{'schema_ref': 'config.ServiceAccountCredentials:4361121312', 'type': 'definition-ref'}, {'schema_ref': 'config.OAuth2Credentials:4965600480', 'type': 'definition-ref'}], 'type': 'union'}

    def apply(self, schema: core_schema.CoreSchema) -> core_schema.CoreSchema:
        """Return a new CoreSchema based on `schema` that uses a tagged-union with the discriminator provided
        to this class.
    
        Args:
            schema: The input schema.
    
        Returns:
            The new core schema.
    
        Raises:
            TypeError:
                - If `discriminator` is used with invalid union variant.
                - If `discriminator` is used with `Union` type with one variant.
                - If `discriminator` value mapped to multiple choices.
            ValueError:
                If the definition for ref is missing.
            PydanticUserError:
                - If a model in union doesn't have a discriminator field.
                - If discriminator field has a non-string alias.
                - If discriminator fields have different aliases.
                - If discriminator field not of type `Literal`.
        """
        assert not self._used
>       schema = self._apply_to_root(schema)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:164: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x103e5c590>
schema = {'choices': [{'schema_ref': 'config.ServiceAccountCredentials:4361121312', 'type': 'definition-ref'}, {'schema_ref': 'config.OAuth2Credentials:4965600480', 'type': 'definition-ref'}], 'type': 'union'}

    def _apply_to_root(self, schema: core_schema.CoreSchema) -> core_schema.CoreSchema:
        """This method handles the outer-most stage of recursion over the input schema:
        unwrapping nullable or definitions schemas, and calling the `_handle_choice`
        method iteratively on the choices extracted (recursively) from the possibly-wrapped union.
        """
        if schema['type'] == 'nullable':
            self._is_nullable = True
            wrapped = self._apply_to_root(schema['schema'])
            nullable_wrapper = schema.copy()
            nullable_wrapper['schema'] = wrapped
            return nullable_wrapper
    
        if schema['type'] == 'definitions':
            wrapped = self._apply_to_root(schema['schema'])
            definitions_wrapper = schema.copy()
            definitions_wrapper['schema'] = wrapped
            return definitions_wrapper
    
        if schema['type'] != 'union':
            # If the schema is not a union, it probably means it just had a single member and
            # was flattened by pydantic_core.
            # However, it still may make sense to apply the discriminator to this schema,
            # as a way to get discriminated-union-style error messages, so we allow this here.
            schema = core_schema.union_schema([schema])
    
        # Reverse the choices list before extending the stack so that they get handled in the order they occur
        choices_schemas = [v[0] if isinstance(v, tuple) else v for v in schema['choices'][::-1]]
        self._choices_to_handle.extend(choices_schemas)
        while self._choices_to_handle:
            choice = self._choices_to_handle.pop()
>           self._handle_choice(choice)

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x103e5c590>
choice = {'schema_ref': 'config.ServiceAccountCredentials:4361121312', 'type': 'definition-ref'}

    def _handle_choice(self, choice: core_schema.CoreSchema) -> None:
        """This method handles the "middle" stage of recursion over the input schema.
        Specifically, it is responsible for handling each choice of the outermost union
        (and any "coalesced" choices obtained from inner unions).
    
        Here, "handling" entails:
        * Coalescing nested unions and compatible tagged-unions
        * Tracking the presence of 'none' and 'nullable' schemas occurring as choices
        * Validating that each allowed discriminator value maps to a unique choice
        * Updating the _tagged_union_choices mapping that will ultimately be used to build the TaggedUnionSchema.
        """
        if choice['type'] == 'definition-ref':
            if choice['schema_ref'] not in self.definitions:
                raise MissingDefinitionForUnionRef(choice['schema_ref'])
    
        if choice['type'] == 'none':
            self._should_be_nullable = True
        elif choice['type'] == 'definitions':
            self._handle_choice(choice['schema'])
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            self._handle_choice(choice['schema'])  # unwrap the nullable schema
        elif choice['type'] == 'union':
            # Reverse the choices list before extending the stack so that they get handled in the order they occur
            choices_schemas = [v[0] if isinstance(v, tuple) else v for v in choice['choices'][::-1]]
            self._choices_to_handle.extend(choices_schemas)
        elif choice['type'] not in {
            'model',
            'typed-dict',
            'tagged-union',
            'lax-or-strict',
            'dataclass',
            'dataclass-args',
            'definition-ref',
        } and not _core_utils.is_function_with_inner_schema(choice):
            # We should eventually handle 'definition-ref' as well
            err_str = f'The core schema type {choice["type"]!r} is not a valid discriminated union variant.'
            if choice['type'] == 'list':
                err_str += (
                    ' If you are making use of a list of union types, make sure the discriminator is applied to the '
                    'union type and not the list (e.g. `list[Annotated[<T> | <U>, Field(discriminator=...)]]`).'
                )
            raise TypeError(err_str)
        else:
            if choice['type'] == 'tagged-union' and self._is_discriminator_shared(choice):
                # In this case, this inner tagged-union is compatible with the outer tagged-union,
                # and its choices can be coalesced into the outer TaggedUnionSchema.
                subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
                # Reverse the choices list before extending the stack so that they get handled in the order they occur
                self._choices_to_handle.extend(subchoices[::-1])
                return
    
>           inferred_discriminator_values = self._infer_discriminator_values_for_choice(choice, source_name=None)
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:278: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x103e5c590>
choice = {'schema_ref': 'config.ServiceAccountCredentials:4361121312', 'type': 'definition-ref'}
source_name = None

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif choice['type'] == 'lax-or-strict':
            return sorted(
                set(
                    self._infer_discriminator_values_for_choice(choice['lax_schema'], source_name=None)
                    + self._infer_discriminator_values_for_choice(choice['strict_schema'], source_name=None)
                )
            )
    
        elif choice['type'] == 'tagged-union':
            values: list[str | int] = []
            # Ignore str/int "choices" since these are just references to other choices
            subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
            for subchoice in subchoices:
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'union':
            values = []
            for subchoice in choice['choices']:
                subchoice_schema = subchoice[0] if isinstance(subchoice, tuple) else subchoice
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice_schema, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=None)
    
        elif choice['type'] == 'model':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'dataclass':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'model-fields':
            return self._infer_discriminator_values_for_model_choice(choice, source_name=source_name)
    
        elif choice['type'] == 'dataclass-args':
            return self._infer_discriminator_values_for_dataclass_choice(choice, source_name=source_name)
    
        elif choice['type'] == 'typed-dict':
            return self._infer_discriminator_values_for_typed_dict_choice(choice, source_name=source_name)
    
        elif choice['type'] == 'definition-ref':
            schema_ref = choice['schema_ref']
            if schema_ref not in self.definitions:
                raise MissingDefinitionForUnionRef(schema_ref)
>           return self._infer_discriminator_values_for_choice(self.definitions[schema_ref], source_name=source_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x103e5c590>
choice = {'function': {'function': <function ServiceAccountCredentials.validate_credentials_source at 0x103979bc0>, 'type': 'no...tCredentials'>, 'config': {'title': 'ServiceAccountCredentials'}, 'custom_init': False, 'root_model': False, ...}, ...}
source_name = None

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
>           return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:304: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x103e5c590>
choice = {'cls': <class 'config.ServiceAccountCredentials'>, 'config': {'title': 'ServiceAccountCredentials'}, 'custom_init': False, 'root_model': False, ...}
source_name = None

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif choice['type'] == 'lax-or-strict':
            return sorted(
                set(
                    self._infer_discriminator_values_for_choice(choice['lax_schema'], source_name=None)
                    + self._infer_discriminator_values_for_choice(choice['strict_schema'], source_name=None)
                )
            )
    
        elif choice['type'] == 'tagged-union':
            values: list[str | int] = []
            # Ignore str/int "choices" since these are just references to other choices
            subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
            for subchoice in subchoices:
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'union':
            values = []
            for subchoice in choice['choices']:
                subchoice_schema = subchoice[0] if isinstance(subchoice, tuple) else subchoice
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice_schema, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=None)
    
        elif choice['type'] == 'model':
>           return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x103e5c590>
choice = {'computed_fields': [], 'fields': {'auth_type': {'metadata': {'pydantic_js_updates': {'description': 'Authentication t...fore'}, 'type': 'default'}, 'type': 'model-field'}}, 'model_name': 'ServiceAccountCredentials', 'type': 'model-fields'}
source_name = 'ServiceAccountCredentials'

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif choice['type'] == 'lax-or-strict':
            return sorted(
                set(
                    self._infer_discriminator_values_for_choice(choice['lax_schema'], source_name=None)
                    + self._infer_discriminator_values_for_choice(choice['strict_schema'], source_name=None)
                )
            )
    
        elif choice['type'] == 'tagged-union':
            values: list[str | int] = []
            # Ignore str/int "choices" since these are just references to other choices
            subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
            for subchoice in subchoices:
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'union':
            values = []
            for subchoice in choice['choices']:
                subchoice_schema = subchoice[0] if isinstance(subchoice, tuple) else subchoice
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice_schema, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=None)
    
        elif choice['type'] == 'model':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'dataclass':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'model-fields':
>           return self._infer_discriminator_values_for_model_choice(choice, source_name=source_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:342: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x103e5c590>
choice = {'computed_fields': [], 'fields': {'auth_type': {'metadata': {'pydantic_js_updates': {'description': 'Authentication t...fore'}, 'type': 'default'}, 'type': 'model-field'}}, 'model_name': 'ServiceAccountCredentials', 'type': 'model-fields'}
source_name = 'ServiceAccountCredentials'

    def _infer_discriminator_values_for_model_choice(
        self, choice: core_schema.ModelFieldsSchema, source_name: str | None = None
    ) -> list[str | int]:
        source = 'ModelFields' if source_name is None else f'Model {source_name!r}'
        field = choice['fields'].get(self.discriminator)
        if field is None:
            raise PydanticUserError(
                f'{source} needs a discriminator field for key {self.discriminator!r}', code='discriminator-no-field'
            )
>       return self._infer_discriminator_values_for_field(field, source)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x103e5c590>
field = {'metadata': {'pydantic_js_updates': {'description': 'Authentication type identifier'}}, 'schema': {'default': <AuthTy...et_json_schema at 0x103e98d60>]}, 'ref': 'config.AuthType:4361119552', ...}, 'type': 'default'}, 'type': 'model-field'}
source = "Model 'ServiceAccountCredentials'"

    def _infer_discriminator_values_for_field(self, field: CoreSchemaField, source: str) -> list[str | int]:
        if field['type'] == 'computed-field':
            # This should never occur as a discriminator, as it is only relevant to serialization
            return []
        alias = field.get('validation_alias', self.discriminator)
        if not isinstance(alias, str):
            raise PydanticUserError(
                f'Alias {alias!r} is not supported in a discriminated union', code='discriminator-alias-type'
            )
        if self._discriminator_alias is None:
            self._discriminator_alias = alias
        elif self._discriminator_alias != alias:
            raise PydanticUserError(
                f'Aliases for discriminator {self.discriminator!r} must be the same '
                f'(got {alias}, {self._discriminator_alias})',
                code='discriminator-alias',
            )
>       return self._infer_discriminator_values_for_inner_schema(field['schema'], source)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:419: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x103e5c590>
schema = {'default': <AuthType.SERVICE_ACCOUNT: 'service_account'>, 'schema': {'cls': <enum 'AuthType'>, 'members': [<AuthType....._enum_schema.<locals>.get_json_schema at 0x103e98d60>]}, 'ref': 'config.AuthType:4361119552', ...}, 'type': 'default'}
source = "Model 'ServiceAccountCredentials'"

    def _infer_discriminator_values_for_inner_schema(
        self, schema: core_schema.CoreSchema, source: str
    ) -> list[str | int]:
        """When inferring discriminator values for a field, we typically extract the expected values from a literal
        schema. This function does that, but also handles nested unions and defaults.
        """
        if schema['type'] == 'literal':
            return schema['expected']
    
        elif schema['type'] == 'union':
            # Generally when multiple values are allowed they should be placed in a single `Literal`, but
            # we add this case to handle the situation where a field is annotated as a `Union` of `Literal`s.
            # For example, this lets us handle `Union[Literal['key'], Union[Literal['Key'], Literal['KEY']]]`
            values: list[Any] = []
            for choice in schema['choices']:
                choice_schema = choice[0] if isinstance(choice, tuple) else choice
                choice_values = self._infer_discriminator_values_for_inner_schema(choice_schema, source)
                values.extend(choice_values)
            return values
    
        elif schema['type'] == 'default':
            # This will happen if the field has a default value; we ignore it while extracting the discriminator values
>           return self._infer_discriminator_values_for_inner_schema(schema['schema'], source)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:443: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x103e5c590>
schema = {'cls': <enum 'AuthType'>, 'members': [<AuthType.SERVICE_ACCOUNT: 'service_account'>, <AuthType.OAUTH2: 'oauth2'>], 'm...ction GenerateSchema._enum_schema.<locals>.get_json_schema at 0x103e98d60>]}, 'ref': 'config.AuthType:4361119552', ...}
source = "Model 'ServiceAccountCredentials'"

    def _infer_discriminator_values_for_inner_schema(
        self, schema: core_schema.CoreSchema, source: str
    ) -> list[str | int]:
        """When inferring discriminator values for a field, we typically extract the expected values from a literal
        schema. This function does that, but also handles nested unions and defaults.
        """
        if schema['type'] == 'literal':
            return schema['expected']
    
        elif schema['type'] == 'union':
            # Generally when multiple values are allowed they should be placed in a single `Literal`, but
            # we add this case to handle the situation where a field is annotated as a `Union` of `Literal`s.
            # For example, this lets us handle `Union[Literal['key'], Union[Literal['Key'], Literal['KEY']]]`
            values: list[Any] = []
            for choice in schema['choices']:
                choice_schema = choice[0] if isinstance(choice, tuple) else choice
                choice_values = self._infer_discriminator_values_for_inner_schema(choice_schema, source)
                values.extend(choice_values)
            return values
    
        elif schema['type'] == 'default':
            # This will happen if the field has a default value; we ignore it while extracting the discriminator values
            return self._infer_discriminator_values_for_inner_schema(schema['schema'], source)
    
        elif schema['type'] == 'function-after':
            # After validators don't affect the discriminator values
            return self._infer_discriminator_values_for_inner_schema(schema['schema'], source)
    
        elif schema['type'] in {'function-before', 'function-wrap', 'function-plain'}:
            validator_type = repr(schema['type'].split('-')[1])
            raise PydanticUserError(
                f'Cannot use a mode={validator_type} validator in the'
                f' discriminator field {self.discriminator!r} of {source}',
                code='discriminator-validator',
            )
    
        else:
>           raise PydanticUserError(
                f'{source} needs field {self.discriminator!r} to be of type `Literal`',
                code='discriminator-needs-literal',
            )
E           pydantic.errors.PydanticUserError: Model 'ServiceAccountCredentials' needs field 'auth_type' to be of type `Literal`
E           
E           For further information visit https://errors.pydantic.dev/2.12/u/discriminator-needs-literal

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:458: PydanticUserError
_____________________ ERROR collecting test_connection.py ______________________

    """
    Test connection checking for Google Sheets connector.
    
    Tests:
    - Connection check with valid credentials
    - Connection check with invalid credentials
    - Error handling for various failure modes
    """
    
    import sys
    import os
    import pytest
    from unittest.mock import Mock, patch, MagicMock
    
    # Add src to path
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))
    
>   from connector import GoogleSheetsConnector, ConnectionCheckResult, ConnectorStatus

tests/test_connection.py:18: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Main Google Sheets connector implementation.
    
    Provides the primary interface for connecting to Google Sheets,
    discovering available data streams, and reading data.
    """
    
    import json
    import logging
    import sys
    from dataclasses import dataclass
    from enum import Enum
    from typing import Any, Dict, Generator, Iterator, List, Optional, Union
    
>   from src.auth import (
        GoogleSheetsAuthenticator,
        ServiceAccountAuth,
        OAuth2Auth,
        AuthenticationError,
        create_authenticator,
    )

src/connector.py:15: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Google Sheets Source Connector
    
    A production-ready connector for extracting data from Google Sheets.
    Supports OAuth2 and Service Account authentication methods.
    """
    
    from src.auth import (
        GoogleSheetsAuthenticator,
        ServiceAccountAuth,
        OAuth2Auth,
        AuthenticationError,
    )
    from src.client import GoogleSheetsClient, GoogleSheetsAPIError
>   from src.config import (
        GoogleSheetsConfig,
        ServiceAccountCredentials,
        OAuth2Credentials,
    )

src/__init__.py:15: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Configuration models for Google Sheets connector using Pydantic.
    
    Provides validation and type safety for connector configuration.
    """
    
    import json
    import re
    from enum import Enum
    from typing import Any, Dict, List, Optional, Union
    
    from pydantic import BaseModel, Field, field_validator, model_validator
    
    
    class AuthType(str, Enum):
        """Supported authentication types."""
    
        SERVICE_ACCOUNT = "service_account"
        OAUTH2 = "oauth2"
    
    
    class ServiceAccountCredentials(BaseModel):
        """Configuration for Service Account authentication."""
    
        auth_type: AuthType = Field(
            default=AuthType.SERVICE_ACCOUNT,
            description="Authentication type identifier",
        )
        service_account_info: Optional[Union[str, Dict[str, Any]]] = Field(
            default=None,
            description="Service account JSON key as string or dictionary",
        )
        service_account_file: Optional[str] = Field(
            default=None,
            description="Path to service account JSON key file",
        )
    
        @model_validator(mode="after")
        def validate_credentials_source(self) -> "ServiceAccountCredentials":
            """Ensure at least one credential source is provided."""
            if not self.service_account_info and not self.service_account_file:
                raise ValueError(
                    "Must provide either service_account_info or service_account_file"
                )
            return self
    
        @field_validator("service_account_info", mode="before")
        @classmethod
        def parse_service_account_info(cls, v: Optional[Union[str, Dict]]) -> Optional[Dict]:
            """Parse service account info from string if needed."""
            if v is None:
                return None
            if isinstance(v, str):
                try:
                    return json.loads(v)
                except json.JSONDecodeError as e:
                    raise ValueError(f"Invalid JSON in service_account_info: {e}")
            return v
    
    
    class OAuth2Credentials(BaseModel):
        """Configuration for OAuth2 authentication."""
    
        auth_type: AuthType = Field(
            default=AuthType.OAUTH2,
            description="Authentication type identifier",
        )
        client_id: str = Field(
            ...,
            min_length=1,
            description="OAuth2 client ID",
        )
        client_secret: str = Field(
            ...,
            min_length=1,
            description="OAuth2 client secret",
        )
        refresh_token: str = Field(
            ...,
            min_length=1,
            description="OAuth2 refresh token",
        )
        access_token: Optional[str] = Field(
            default=None,
            description="Optional existing access token",
        )
    
    
    # Union type for credentials
    CredentialsConfig = Union[ServiceAccountCredentials, OAuth2Credentials]
    
    
    class StreamSelection(BaseModel):
        """Configuration for selecting which streams/sheets to sync."""
    
        sheet_names: Optional[List[str]] = Field(
            default=None,
            description="List of sheet names to sync. If None, all sheets are synced.",
        )
        exclude_sheets: Optional[List[str]] = Field(
            default=None,
            description="List of sheet names to exclude from sync.",
        )
    
    
>   class GoogleSheetsConfig(BaseModel):

src/config.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

mcs = <class 'pydantic._internal._model_construction.ModelMetaclass'>
cls_name = 'GoogleSheetsConfig', bases = (<class 'pydantic.main.BaseModel'>,)
namespace = {'__module__': 'src.config', '__qualname__': 'GoogleSheetsConfig', '__firstlineno__': 106, '__annotations__': {'spread...t 0x1069b7880>, '__static_attributes__': (), 'model_config': {}, '__class_vars__': set(), '__private_attributes__': {}}
__pydantic_generic_metadata__ = None, __pydantic_reset_parent_namespace__ = True
_create_model_module = None, kwargs = {}
raw_annotations = {'credentials': typing.Union[src.config.ServiceAccountCredentials, src.config.OAuth2Credentials], 'date_time_render_option': <class 'str'>, 'include_row_number': <class 'bool'>, 'requests_per_minute': <class 'int'>, ...}
base_field_names = set(), class_vars = set()

    def __new__(
        mcs,
        cls_name: str,
        bases: tuple[type[Any], ...],
        namespace: dict[str, Any],
        __pydantic_generic_metadata__: PydanticGenericMetadata | None = None,
        __pydantic_reset_parent_namespace__: bool = True,
        _create_model_module: str | None = None,
        **kwargs: Any,
    ) -> type:
        """Metaclass for creating Pydantic models.
    
        Args:
            cls_name: The name of the class to be created.
            bases: The base classes of the class to be created.
            namespace: The attribute dictionary of the class to be created.
            __pydantic_generic_metadata__: Metadata for generic models.
            __pydantic_reset_parent_namespace__: Reset parent namespace.
            _create_model_module: The module of the class to be created, if created by `create_model`.
            **kwargs: Catch-all for any other keyword arguments.
    
        Returns:
            The new class created by the metaclass.
        """
        # Note `ModelMetaclass` refers to `BaseModel`, but is also used to *create* `BaseModel`, so we rely on the fact
        # that `BaseModel` itself won't have any bases, but any subclass of it will, to determine whether the `__new__`
        # call we're in the middle of is for the `BaseModel` class.
        if bases:
            raw_annotations: dict[str, Any]
            if sys.version_info >= (3, 14):
                if (
                    '__annotations__' in namespace
                ):  # `from __future__ import annotations` was used in the model's module
                    raw_annotations = namespace['__annotations__']
                else:
                    # See https://docs.python.org/3.14/library/annotationlib.html#using-annotations-in-a-metaclass:
                    from annotationlib import Format, call_annotate_function, get_annotate_from_class_namespace
    
                    if annotate := get_annotate_from_class_namespace(namespace):
                        raw_annotations = call_annotate_function(annotate, format=Format.FORWARDREF)
                    else:
                        raw_annotations = {}
            else:
                raw_annotations = namespace.get('__annotations__', {})
    
            base_field_names, class_vars, base_private_attributes = mcs._collect_bases_data(bases)
    
            config_wrapper = ConfigWrapper.for_model(bases, namespace, raw_annotations, kwargs)
            namespace['model_config'] = config_wrapper.config_dict
            private_attributes = inspect_namespace(
                namespace, raw_annotations, config_wrapper.ignored_types, class_vars, base_field_names
            )
            if private_attributes or base_private_attributes:
                original_model_post_init = get_model_post_init(namespace, bases)
                if original_model_post_init is not None:
                    # if there are private_attributes and a model_post_init function, we handle both
    
                    @wraps(original_model_post_init)
                    def wrapped_model_post_init(self: BaseModel, context: Any, /) -> None:
                        """We need to both initialize private attributes and call the user-defined model_post_init
                        method.
                        """
                        init_private_attributes(self, context)
                        original_model_post_init(self, context)
    
                    namespace['model_post_init'] = wrapped_model_post_init
                else:
                    namespace['model_post_init'] = init_private_attributes
    
            namespace['__class_vars__'] = class_vars
            namespace['__private_attributes__'] = {**base_private_attributes, **private_attributes}
    
            cls = cast('type[BaseModel]', super().__new__(mcs, cls_name, bases, namespace, **kwargs))
            BaseModel_ = import_cached_base_model()
    
            mro = cls.__mro__
            if Generic in mro and mro.index(Generic) < mro.index(BaseModel_):
                warnings.warn(
                    GenericBeforeBaseModelWarning(
                        'Classes should inherit from `BaseModel` before generic classes (e.g. `typing.Generic[T]`) '
                        'for pydantic generics to work properly.'
                    ),
                    stacklevel=2,
                )
    
            cls.__pydantic_custom_init__ = not getattr(cls.__init__, '__pydantic_base_init__', False)
            cls.__pydantic_post_init__ = (
                None if cls.model_post_init is BaseModel_.model_post_init else 'model_post_init'
            )
    
            cls.__pydantic_setattr_handlers__ = {}
    
            cls.__pydantic_decorators__ = DecoratorInfos.build(cls)
            cls.__pydantic_decorators__.update_from_config(config_wrapper)
    
            # Use the getattr below to grab the __parameters__ from the `typing.Generic` parent class
            if __pydantic_generic_metadata__:
                cls.__pydantic_generic_metadata__ = __pydantic_generic_metadata__
            else:
                parent_parameters = getattr(cls, '__pydantic_generic_metadata__', {}).get('parameters', ())
                parameters = getattr(cls, '__parameters__', None) or parent_parameters
                if parameters and parent_parameters and not all(x in parameters for x in parent_parameters):
                    from ..root_model import RootModelRootType
    
                    missing_parameters = tuple(x for x in parameters if x not in parent_parameters)
                    if RootModelRootType in parent_parameters and RootModelRootType not in parameters:
                        # This is a special case where the user has subclassed `RootModel`, but has not parametrized
                        # RootModel with the generic type identifiers being used. Ex:
                        # class MyModel(RootModel, Generic[T]):
                        #    root: T
                        # Should instead just be:
                        # class MyModel(RootModel[T]):
                        #   root: T
                        parameters_str = ', '.join([x.__name__ for x in missing_parameters])
                        error_message = (
                            f'{cls.__name__} is a subclass of `RootModel`, but does not include the generic type identifier(s) '
                            f'{parameters_str} in its parameters. '
                            f'You should parametrize RootModel directly, e.g., `class {cls.__name__}(RootModel[{parameters_str}]): ...`.'
                        )
                    else:
                        combined_parameters = parent_parameters + missing_parameters
                        parameters_str = ', '.join([str(x) for x in combined_parameters])
                        generic_type_label = f'typing.Generic[{parameters_str}]'
                        error_message = (
                            f'All parameters must be present on typing.Generic;'
                            f' you should inherit from {generic_type_label}.'
                        )
                        if Generic not in bases:  # pragma: no cover
                            # We raise an error here not because it is desirable, but because some cases are mishandled.
                            # It would be nice to remove this error and still have things behave as expected, it's just
                            # challenging because we are using a custom `__class_getitem__` to parametrize generic models,
                            # and not returning a typing._GenericAlias from it.
                            bases_str = ', '.join([x.__name__ for x in bases] + [generic_type_label])
                            error_message += (
                                f' Note: `typing.Generic` must go last: `class {cls.__name__}({bases_str}): ...`)'
                            )
                    raise TypeError(error_message)
    
                cls.__pydantic_generic_metadata__ = {
                    'origin': None,
                    'args': (),
                    'parameters': parameters,
                }
    
            cls.__pydantic_complete__ = False  # Ensure this specific class gets completed
    
            # preserve `__set_name__` protocol defined in https://peps.python.org/pep-0487
            # for attributes not in `new_namespace` (e.g. private attributes)
            for name, obj in private_attributes.items():
                obj.__set_name__(cls, name)
    
            if __pydantic_reset_parent_namespace__:
                cls.__pydantic_parent_namespace__ = build_lenient_weakvaluedict(parent_frame_namespace())
            parent_namespace: dict[str, Any] | None = getattr(cls, '__pydantic_parent_namespace__', None)
            if isinstance(parent_namespace, dict):
                parent_namespace = unpack_lenient_weakvaluedict(parent_namespace)
    
            ns_resolver = NsResolver(parent_namespace=parent_namespace)
    
            set_model_fields(cls, config_wrapper=config_wrapper, ns_resolver=ns_resolver)
    
            # This is also set in `complete_model_class()`, after schema gen because they are recreated.
            # We set them here as well for backwards compatibility:
            cls.__pydantic_computed_fields__ = {
                k: v.info for k, v in cls.__pydantic_decorators__.computed_fields.items()
            }
    
            if config_wrapper.defer_build:
                set_model_mocks(cls)
            else:
                # Any operation that requires accessing the field infos instances should be put inside
                # `complete_model_class()`:
>               complete_model_class(
                    cls,
                    config_wrapper,
                    ns_resolver,
                    raise_errors=False,
                    create_model_module=_create_model_module,
                )

venv/lib/python3.13/site-packages/pydantic/_internal/_model_construction.py:255: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'src.config.GoogleSheetsConfig'>, config_wrapper = ConfigWrapper()
ns_resolver = <pydantic._internal._namespace_utils.NsResolver object at 0x106996cf0>

    def complete_model_class(
        cls: type[BaseModel],
        config_wrapper: ConfigWrapper,
        ns_resolver: NsResolver,
        *,
        raise_errors: bool = True,
        call_on_complete_hook: bool = True,
        create_model_module: str | None = None,
    ) -> bool:
        """Finish building a model class.
    
        This logic must be called after class has been created since validation functions must be bound
        and `get_type_hints` requires a class object.
    
        Args:
            cls: BaseModel or dataclass.
            config_wrapper: The config wrapper instance.
            ns_resolver: The namespace resolver instance to use during schema building.
            raise_errors: Whether to raise errors.
            call_on_complete_hook: Whether to call the `__pydantic_on_complete__` hook.
            create_model_module: The module of the class to be created, if created by `create_model`.
    
        Returns:
            `True` if the model is successfully completed, else `False`.
    
        Raises:
            PydanticUndefinedAnnotation: If `PydanticUndefinedAnnotation` occurs in`__get_pydantic_core_schema__`
                and `raise_errors=True`.
        """
        typevars_map = get_model_typevars_map(cls)
    
        if not cls.__pydantic_fields_complete__:
            # Note: when coming from `ModelMetaclass.__new__()`, this results in fields being built twice.
            # We do so a second time here so that we can get the `NameError` for the specific undefined annotation.
            # Alternatively, we could let `GenerateSchema()` raise the error, but there are cases where incomplete
            # fields are inherited in `collect_model_fields()` and can actually have their annotation resolved in the
            # generate schema process. As we want to avoid having `__pydantic_fields_complete__` set to `False`
            # when `__pydantic_complete__` is `True`, we rebuild here:
            try:
                cls.__pydantic_fields__ = rebuild_model_fields(
                    cls,
                    config_wrapper=config_wrapper,
                    ns_resolver=ns_resolver,
                    typevars_map=typevars_map,
                )
            except NameError as e:
                exc = PydanticUndefinedAnnotation.from_name_error(e)
                set_model_mocks(cls, f'`{exc.name}`')
                if raise_errors:
                    raise exc from e
    
            if not raise_errors and not cls.__pydantic_fields_complete__:
                # No need to continue with schema gen, it is guaranteed to fail
                return False
    
            assert cls.__pydantic_fields_complete__
    
        gen_schema = GenerateSchema(
            config_wrapper,
            ns_resolver,
            typevars_map,
        )
    
        try:
>           schema = gen_schema.generate_schema(cls)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_model_construction.py:648: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x103e6f290>
obj = <class 'src.config.GoogleSheetsConfig'>

    def generate_schema(
        self,
        obj: Any,
    ) -> core_schema.CoreSchema:
        """Generate core schema.
    
        Args:
            obj: The object to generate core schema for.
    
        Returns:
            The generated core schema.
    
        Raises:
            PydanticUndefinedAnnotation:
                If it is not possible to evaluate forward reference.
            PydanticSchemaGenerationError:
                If it is not possible to generate pydantic-core schema.
            TypeError:
                - If `alias_generator` returns a disallowed type (must be str, AliasPath or AliasChoices).
                - If V1 style validator with `each_item=True` applied on a wrong field.
            PydanticUserError:
                - If `typing.TypedDict` is used instead of `typing_extensions.TypedDict` on Python < 3.12.
                - If `__modify_schema__` method is used instead of `__get_pydantic_json_schema__`.
        """
        schema = self._generate_schema_from_get_schema_method(obj, obj)
    
        if schema is None:
>           schema = self._generate_schema_inner(obj)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x103e6f290>
obj = <class 'src.config.GoogleSheetsConfig'>

    def _generate_schema_inner(self, obj: Any) -> core_schema.CoreSchema:
        if typing_objects.is_self(obj):
            obj = self._resolve_self_type(obj)
    
        if typing_objects.is_annotated(get_origin(obj)):
            return self._annotated_schema(obj)
    
        if isinstance(obj, dict):
            # we assume this is already a valid schema
            return obj  # type: ignore[return-value]
    
        if isinstance(obj, str):
            obj = ForwardRef(obj)
    
        if isinstance(obj, ForwardRef):
            return self.generate_schema(self._resolve_forward_ref(obj))
    
        BaseModel = import_cached_base_model()
    
        if lenient_issubclass(obj, BaseModel):
            with self.model_type_stack.push(obj):
>               return self._model_schema(obj)
                       ^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1023: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x103e6f290>
cls = <class 'src.config.GoogleSheetsConfig'>

    def _model_schema(self, cls: type[BaseModel]) -> core_schema.CoreSchema:
        """Generate schema for a Pydantic model."""
        BaseModel_ = import_cached_base_model()
    
        with self.defs.get_schema_or_ref(cls) as (model_ref, maybe_schema):
            if maybe_schema is not None:
                return maybe_schema
    
            schema = cls.__dict__.get('__pydantic_core_schema__')
            if schema is not None and not isinstance(schema, MockCoreSchema):
                if schema['type'] == 'definitions':
                    schema = self.defs.unpack_definitions(schema)
                ref = get_ref(schema)
                if ref:
                    return self.defs.create_definition_reference_schema(schema)
                else:
                    return schema
    
            config_wrapper = ConfigWrapper(cls.model_config, check=False)
    
            with self._config_wrapper_stack.push(config_wrapper), self._ns_resolver.push(cls):
                core_config = self._config_wrapper.core_config(title=cls.__name__)
    
                if cls.__pydantic_fields_complete__ or cls is BaseModel_:
                    fields = getattr(cls, '__pydantic_fields__', {})
                else:
                    if '__pydantic_fields__' not in cls.__dict__:
                        # This happens when we have a loop in the schema generation:
                        # class Base[T](BaseModel):
                        #     t: T
                        #
                        # class Other(BaseModel):
                        #     b: 'Base[Other]'
                        # When we build fields for `Other`, we evaluate the forward annotation.
                        # At this point, `Other` doesn't have the model fields set. We create
                        # `Base[Other]`; model fields are successfully built, and we try to generate
                        # a schema for `t: Other`. As `Other.__pydantic_fields__` aren't set, we abort.
                        raise PydanticUndefinedAnnotation(
                            name=cls.__name__,
                            message=f'Class {cls.__name__!r} is not defined',
                        )
                    try:
                        fields = rebuild_model_fields(
                            cls,
                            config_wrapper=self._config_wrapper,
                            ns_resolver=self._ns_resolver,
                            typevars_map=self._typevars_map or {},
                        )
                    except NameError as e:
                        raise PydanticUndefinedAnnotation.from_name_error(e) from e
    
                decorators = cls.__pydantic_decorators__
                computed_fields = decorators.computed_fields
                check_decorator_fields_exist(
                    chain(
                        decorators.field_validators.values(),
                        decorators.field_serializers.values(),
                        decorators.validators.values(),
                    ),
                    {*fields.keys(), *computed_fields.keys()},
                )
    
                model_validators = decorators.model_validators.values()
    
                extras_schema = None
                extras_keys_schema = None
                if core_config.get('extra_fields_behavior') == 'allow':
                    assert cls.__mro__[0] is cls
                    assert cls.__mro__[-1] is object
                    for candidate_cls in cls.__mro__[:-1]:
                        extras_annotation = getattr(candidate_cls, '__annotations__', {}).get(
                            '__pydantic_extra__', None
                        )
                        if extras_annotation is not None:
                            if isinstance(extras_annotation, str):
                                extras_annotation = _typing_extra.eval_type_backport(
                                    _typing_extra._make_forward_ref(
                                        extras_annotation, is_argument=False, is_class=True
                                    ),
                                    *self._types_namespace,
                                )
                            tp = get_origin(extras_annotation)
                            if tp not in DICT_TYPES:
                                raise PydanticSchemaGenerationError(
                                    'The type annotation for `__pydantic_extra__` must be `dict[str, ...]`'
                                )
                            extra_keys_type, extra_items_type = self._get_args_resolving_forward_refs(
                                extras_annotation,
                                required=True,
                            )
                            if extra_keys_type is not str:
                                extras_keys_schema = self.generate_schema(extra_keys_type)
                            if not typing_objects.is_any(extra_items_type):
                                extras_schema = self.generate_schema(extra_items_type)
                            if extras_keys_schema is not None or extras_schema is not None:
                                break
    
                generic_origin: type[BaseModel] | None = getattr(cls, '__pydantic_generic_metadata__', {}).get('origin')
    
                if cls.__pydantic_root_model__:
                    # FIXME: should the common field metadata be used here?
                    inner_schema, _ = self._common_field_schema('root', fields['root'], decorators)
                    inner_schema = apply_model_validators(inner_schema, model_validators, 'inner')
                    model_schema = core_schema.model_schema(
                        cls,
                        inner_schema,
                        generic_origin=generic_origin,
                        custom_init=getattr(cls, '__pydantic_custom_init__', None),
                        root_model=True,
                        post_init=getattr(cls, '__pydantic_post_init__', None),
                        config=core_config,
                        ref=model_ref,
                    )
                else:
                    fields_schema: core_schema.CoreSchema = core_schema.model_fields_schema(
>                       {k: self._generate_md_field_schema(k, v, decorators) for k, v in fields.items()},
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                        computed_fields=[
                            self._computed_field_schema(d, decorators.field_serializers)
                            for d in computed_fields.values()
                        ],
                        extras_schema=extras_schema,
                        extras_keys_schema=extras_keys_schema,
                        model_name=cls.__name__,
                    )

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:856: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x103e6f290>
name = 'credentials'
field_info = FieldInfo(annotation=Union[ServiceAccountCredentials, OAuth2Credentials], required=True, description='Authentication credentials', discriminator='auth_type')
decorators = DecoratorInfos(validators={}, field_validators={'extract_spreadsheet_id': Decorator(cls_ref='src.config.GoogleSheetsCo...cUndefined))}, root_validators={}, field_serializers={}, model_serializers={}, model_validators={}, computed_fields={})

    def _generate_md_field_schema(
        self,
        name: str,
        field_info: FieldInfo,
        decorators: DecoratorInfos,
    ) -> core_schema.ModelField:
        """Prepare a ModelField to represent a model field."""
>       schema, metadata = self._common_field_schema(name, field_info, decorators)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x103e6f290>
name = 'credentials'
field_info = FieldInfo(annotation=Union[ServiceAccountCredentials, OAuth2Credentials], required=True, description='Authentication credentials', discriminator='auth_type')
decorators = DecoratorInfos(validators={}, field_validators={'extract_spreadsheet_id': Decorator(cls_ref='src.config.GoogleSheetsCo...cUndefined))}, root_validators={}, field_serializers={}, model_serializers={}, model_validators={}, computed_fields={})

    def _common_field_schema(  # C901
        self, name: str, field_info: FieldInfo, decorators: DecoratorInfos
    ) -> tuple[CoreSchema, dict[str, Any]]:
        source_type, annotations = field_info.annotation, field_info.metadata
    
        def set_discriminator(schema: CoreSchema) -> CoreSchema:
            schema = self._apply_discriminator_to_union(schema, field_info.discriminator)
            return schema
    
        # Convert `@field_validator` decorators to `Before/After/Plain/WrapValidator` instances:
        validators_from_decorators = [
            _mode_to_validator[decorator.info.mode]._from_decorator(decorator)
            for decorator in filter_field_decorator_info_by_field(decorators.field_validators.values(), name)
        ]
    
        with self.field_name_stack.push(name):
            if field_info.discriminator is not None:
>               schema = self._apply_annotations(
                    source_type, annotations + validators_from_decorators, transform_inner_schema=set_discriminator
                )

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1278: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x103e6f290>
source_type = typing.Union[src.config.ServiceAccountCredentials, src.config.OAuth2Credentials]
annotations = []
transform_inner_schema = <function GenerateSchema._common_field_schema.<locals>.set_discriminator at 0x1069b7920>
check_unsupported_field_info_attributes = True

    def _apply_annotations(
        self,
        source_type: Any,
        annotations: list[Any],
        transform_inner_schema: Callable[[CoreSchema], CoreSchema] = lambda x: x,
        check_unsupported_field_info_attributes: bool = True,
    ) -> CoreSchema:
        """Apply arguments from `Annotated` or from `FieldInfo` to a schema.
    
        This gets called by `GenerateSchema._annotated_schema` but differs from it in that it does
        not expect `source_type` to be an `Annotated` object, it expects it to be  the first argument of that
        (in other words, `GenerateSchema._annotated_schema` just unpacks `Annotated`, this process it).
        """
        annotations = list(_known_annotated_metadata.expand_grouped_metadata(annotations))
    
        pydantic_js_annotation_functions: list[GetJsonSchemaFunction] = []
    
        def inner_handler(obj: Any) -> CoreSchema:
            schema = self._generate_schema_from_get_schema_method(obj, source_type)
    
            if schema is None:
                schema = self._generate_schema_inner(obj)
    
            metadata_js_function = _extract_get_pydantic_json_schema(obj)
            if metadata_js_function is not None:
                metadata_schema = resolve_original_schema(schema, self.defs)
                if metadata_schema is not None:
                    self._add_js_function(metadata_schema, metadata_js_function)
            return transform_inner_schema(schema)
    
        get_inner_schema = CallbackGetCoreSchemaHandler(inner_handler, self)
    
        for annotation in annotations:
            if annotation is None:
                continue
            get_inner_schema = self._get_wrapped_inner_schema(
                get_inner_schema,
                annotation,
                pydantic_js_annotation_functions,
                check_unsupported_field_info_attributes=check_unsupported_field_info_attributes,
            )
    
>       schema = get_inner_schema(source_type)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2227: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._schema_generation_shared.CallbackGetCoreSchemaHandler object at 0x1069775f0>
source_type = typing.Union[src.config.ServiceAccountCredentials, src.config.OAuth2Credentials]

    def __call__(self, source_type: Any, /) -> core_schema.CoreSchema:
>       schema = self._handler(source_type)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_schema_generation_shared.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = typing.Union[src.config.ServiceAccountCredentials, src.config.OAuth2Credentials]

    def inner_handler(obj: Any) -> CoreSchema:
        schema = self._generate_schema_from_get_schema_method(obj, source_type)
    
        if schema is None:
            schema = self._generate_schema_inner(obj)
    
        metadata_js_function = _extract_get_pydantic_json_schema(obj)
        if metadata_js_function is not None:
            metadata_schema = resolve_original_schema(schema, self.defs)
            if metadata_schema is not None:
                self._add_js_function(metadata_schema, metadata_js_function)
>       return transform_inner_schema(schema)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2213: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

schema = {'choices': [{'schema_ref': 'src.config.ServiceAccountCredentials:4404266928', 'type': 'definition-ref'}, {'schema_ref': 'src.config.OAuth2Credentials:4404275632', 'type': 'definition-ref'}], 'type': 'union'}

    def set_discriminator(schema: CoreSchema) -> CoreSchema:
>       schema = self._apply_discriminator_to_union(schema, field_info.discriminator)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x103e6f290>
schema = {'choices': [{'schema_ref': 'src.config.ServiceAccountCredentials:4404266928', 'type': 'definition-ref'}, {'schema_ref': 'src.config.OAuth2Credentials:4404275632', 'type': 'definition-ref'}], 'type': 'union'}
discriminator = 'auth_type'

    def _apply_discriminator_to_union(
        self, schema: CoreSchema, discriminator: str | Discriminator | None
    ) -> CoreSchema:
        if discriminator is None:
            return schema
        try:
>           return _discriminated_union.apply_discriminator(
                schema,
                discriminator,
                self.defs._definitions,
            )

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:675: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

schema = {'choices': [{'schema_ref': 'src.config.ServiceAccountCredentials:4404266928', 'type': 'definition-ref'}, {'schema_ref': 'src.config.OAuth2Credentials:4404275632', 'type': 'definition-ref'}], 'type': 'union'}
discriminator = 'auth_type'
definitions = {'src.config.OAuth2Credentials:4404275632': {'cls': <class 'src.config.OAuth2Credentials'>, 'config': {'title': 'OAuth...Credentials'>, 'config': {'title': 'ServiceAccountCredentials'}, 'custom_init': False, 'root_model': False, ...}, ...}}

    def apply_discriminator(
        schema: core_schema.CoreSchema,
        discriminator: str | Discriminator,
        definitions: dict[str, core_schema.CoreSchema] | None = None,
    ) -> core_schema.CoreSchema:
        """Applies the discriminator and returns a new core schema.
    
        Args:
            schema: The input schema.
            discriminator: The name of the field which will serve as the discriminator.
            definitions: A mapping of schema ref to schema.
    
        Returns:
            The new core schema.
    
        Raises:
            TypeError:
                - If `discriminator` is used with invalid union variant.
                - If `discriminator` is used with `Union` type with one variant.
                - If `discriminator` value mapped to multiple choices.
            MissingDefinitionForUnionRef:
                If the definition for ref is missing.
            PydanticUserError:
                - If a model in union doesn't have a discriminator field.
                - If discriminator field has a non-string alias.
                - If discriminator fields have different aliases.
                - If discriminator field not of type `Literal`.
        """
        from ..types import Discriminator
    
        if isinstance(discriminator, Discriminator):
            if isinstance(discriminator.discriminator, str):
                discriminator = discriminator.discriminator
            else:
                return discriminator._convert_schema(schema)
    
>       return _ApplyInferredDiscriminator(discriminator, definitions or {}).apply(schema)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
schema = {'choices': [{'schema_ref': 'src.config.ServiceAccountCredentials:4404266928', 'type': 'definition-ref'}, {'schema_ref': 'src.config.OAuth2Credentials:4404275632', 'type': 'definition-ref'}], 'type': 'union'}

    def apply(self, schema: core_schema.CoreSchema) -> core_schema.CoreSchema:
        """Return a new CoreSchema based on `schema` that uses a tagged-union with the discriminator provided
        to this class.
    
        Args:
            schema: The input schema.
    
        Returns:
            The new core schema.
    
        Raises:
            TypeError:
                - If `discriminator` is used with invalid union variant.
                - If `discriminator` is used with `Union` type with one variant.
                - If `discriminator` value mapped to multiple choices.
            ValueError:
                If the definition for ref is missing.
            PydanticUserError:
                - If a model in union doesn't have a discriminator field.
                - If discriminator field has a non-string alias.
                - If discriminator fields have different aliases.
                - If discriminator field not of type `Literal`.
        """
        assert not self._used
>       schema = self._apply_to_root(schema)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:164: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
schema = {'choices': [{'schema_ref': 'src.config.ServiceAccountCredentials:4404266928', 'type': 'definition-ref'}, {'schema_ref': 'src.config.OAuth2Credentials:4404275632', 'type': 'definition-ref'}], 'type': 'union'}

    def _apply_to_root(self, schema: core_schema.CoreSchema) -> core_schema.CoreSchema:
        """This method handles the outer-most stage of recursion over the input schema:
        unwrapping nullable or definitions schemas, and calling the `_handle_choice`
        method iteratively on the choices extracted (recursively) from the possibly-wrapped union.
        """
        if schema['type'] == 'nullable':
            self._is_nullable = True
            wrapped = self._apply_to_root(schema['schema'])
            nullable_wrapper = schema.copy()
            nullable_wrapper['schema'] = wrapped
            return nullable_wrapper
    
        if schema['type'] == 'definitions':
            wrapped = self._apply_to_root(schema['schema'])
            definitions_wrapper = schema.copy()
            definitions_wrapper['schema'] = wrapped
            return definitions_wrapper
    
        if schema['type'] != 'union':
            # If the schema is not a union, it probably means it just had a single member and
            # was flattened by pydantic_core.
            # However, it still may make sense to apply the discriminator to this schema,
            # as a way to get discriminated-union-style error messages, so we allow this here.
            schema = core_schema.union_schema([schema])
    
        # Reverse the choices list before extending the stack so that they get handled in the order they occur
        choices_schemas = [v[0] if isinstance(v, tuple) else v for v in schema['choices'][::-1]]
        self._choices_to_handle.extend(choices_schemas)
        while self._choices_to_handle:
            choice = self._choices_to_handle.pop()
>           self._handle_choice(choice)

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
choice = {'schema_ref': 'src.config.ServiceAccountCredentials:4404266928', 'type': 'definition-ref'}

    def _handle_choice(self, choice: core_schema.CoreSchema) -> None:
        """This method handles the "middle" stage of recursion over the input schema.
        Specifically, it is responsible for handling each choice of the outermost union
        (and any "coalesced" choices obtained from inner unions).
    
        Here, "handling" entails:
        * Coalescing nested unions and compatible tagged-unions
        * Tracking the presence of 'none' and 'nullable' schemas occurring as choices
        * Validating that each allowed discriminator value maps to a unique choice
        * Updating the _tagged_union_choices mapping that will ultimately be used to build the TaggedUnionSchema.
        """
        if choice['type'] == 'definition-ref':
            if choice['schema_ref'] not in self.definitions:
                raise MissingDefinitionForUnionRef(choice['schema_ref'])
    
        if choice['type'] == 'none':
            self._should_be_nullable = True
        elif choice['type'] == 'definitions':
            self._handle_choice(choice['schema'])
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            self._handle_choice(choice['schema'])  # unwrap the nullable schema
        elif choice['type'] == 'union':
            # Reverse the choices list before extending the stack so that they get handled in the order they occur
            choices_schemas = [v[0] if isinstance(v, tuple) else v for v in choice['choices'][::-1]]
            self._choices_to_handle.extend(choices_schemas)
        elif choice['type'] not in {
            'model',
            'typed-dict',
            'tagged-union',
            'lax-or-strict',
            'dataclass',
            'dataclass-args',
            'definition-ref',
        } and not _core_utils.is_function_with_inner_schema(choice):
            # We should eventually handle 'definition-ref' as well
            err_str = f'The core schema type {choice["type"]!r} is not a valid discriminated union variant.'
            if choice['type'] == 'list':
                err_str += (
                    ' If you are making use of a list of union types, make sure the discriminator is applied to the '
                    'union type and not the list (e.g. `list[Annotated[<T> | <U>, Field(discriminator=...)]]`).'
                )
            raise TypeError(err_str)
        else:
            if choice['type'] == 'tagged-union' and self._is_discriminator_shared(choice):
                # In this case, this inner tagged-union is compatible with the outer tagged-union,
                # and its choices can be coalesced into the outer TaggedUnionSchema.
                subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
                # Reverse the choices list before extending the stack so that they get handled in the order they occur
                self._choices_to_handle.extend(subchoices[::-1])
                return
    
>           inferred_discriminator_values = self._infer_discriminator_values_for_choice(choice, source_name=None)
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:278: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
choice = {'schema_ref': 'src.config.ServiceAccountCredentials:4404266928', 'type': 'definition-ref'}
source_name = None

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif choice['type'] == 'lax-or-strict':
            return sorted(
                set(
                    self._infer_discriminator_values_for_choice(choice['lax_schema'], source_name=None)
                    + self._infer_discriminator_values_for_choice(choice['strict_schema'], source_name=None)
                )
            )
    
        elif choice['type'] == 'tagged-union':
            values: list[str | int] = []
            # Ignore str/int "choices" since these are just references to other choices
            subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
            for subchoice in subchoices:
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'union':
            values = []
            for subchoice in choice['choices']:
                subchoice_schema = subchoice[0] if isinstance(subchoice, tuple) else subchoice
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice_schema, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=None)
    
        elif choice['type'] == 'model':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'dataclass':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'model-fields':
            return self._infer_discriminator_values_for_model_choice(choice, source_name=source_name)
    
        elif choice['type'] == 'dataclass-args':
            return self._infer_discriminator_values_for_dataclass_choice(choice, source_name=source_name)
    
        elif choice['type'] == 'typed-dict':
            return self._infer_discriminator_values_for_typed_dict_choice(choice, source_name=source_name)
    
        elif choice['type'] == 'definition-ref':
            schema_ref = choice['schema_ref']
            if schema_ref not in self.definitions:
                raise MissingDefinitionForUnionRef(schema_ref)
>           return self._infer_discriminator_values_for_choice(self.definitions[schema_ref], source_name=source_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
choice = {'function': {'function': <function ServiceAccountCredentials.validate_credentials_source at 0x1069b72e0>, 'type': 'no...tCredentials'>, 'config': {'title': 'ServiceAccountCredentials'}, 'custom_init': False, 'root_model': False, ...}, ...}
source_name = None

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
>           return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:304: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
choice = {'cls': <class 'src.config.ServiceAccountCredentials'>, 'config': {'title': 'ServiceAccountCredentials'}, 'custom_init': False, 'root_model': False, ...}
source_name = None

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif choice['type'] == 'lax-or-strict':
            return sorted(
                set(
                    self._infer_discriminator_values_for_choice(choice['lax_schema'], source_name=None)
                    + self._infer_discriminator_values_for_choice(choice['strict_schema'], source_name=None)
                )
            )
    
        elif choice['type'] == 'tagged-union':
            values: list[str | int] = []
            # Ignore str/int "choices" since these are just references to other choices
            subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
            for subchoice in subchoices:
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'union':
            values = []
            for subchoice in choice['choices']:
                subchoice_schema = subchoice[0] if isinstance(subchoice, tuple) else subchoice
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice_schema, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=None)
    
        elif choice['type'] == 'model':
>           return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
choice = {'computed_fields': [], 'fields': {'auth_type': {'metadata': {'pydantic_js_updates': {'description': 'Authentication t...fore'}, 'type': 'default'}, 'type': 'model-field'}}, 'model_name': 'ServiceAccountCredentials', 'type': 'model-fields'}
source_name = 'ServiceAccountCredentials'

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif choice['type'] == 'lax-or-strict':
            return sorted(
                set(
                    self._infer_discriminator_values_for_choice(choice['lax_schema'], source_name=None)
                    + self._infer_discriminator_values_for_choice(choice['strict_schema'], source_name=None)
                )
            )
    
        elif choice['type'] == 'tagged-union':
            values: list[str | int] = []
            # Ignore str/int "choices" since these are just references to other choices
            subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
            for subchoice in subchoices:
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'union':
            values = []
            for subchoice in choice['choices']:
                subchoice_schema = subchoice[0] if isinstance(subchoice, tuple) else subchoice
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice_schema, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=None)
    
        elif choice['type'] == 'model':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'dataclass':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'model-fields':
>           return self._infer_discriminator_values_for_model_choice(choice, source_name=source_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:342: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
choice = {'computed_fields': [], 'fields': {'auth_type': {'metadata': {'pydantic_js_updates': {'description': 'Authentication t...fore'}, 'type': 'default'}, 'type': 'model-field'}}, 'model_name': 'ServiceAccountCredentials', 'type': 'model-fields'}
source_name = 'ServiceAccountCredentials'

    def _infer_discriminator_values_for_model_choice(
        self, choice: core_schema.ModelFieldsSchema, source_name: str | None = None
    ) -> list[str | int]:
        source = 'ModelFields' if source_name is None else f'Model {source_name!r}'
        field = choice['fields'].get(self.discriminator)
        if field is None:
            raise PydanticUserError(
                f'{source} needs a discriminator field for key {self.discriminator!r}', code='discriminator-no-field'
            )
>       return self._infer_discriminator_values_for_field(field, source)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
field = {'metadata': {'pydantic_js_updates': {'description': 'Authentication type identifier'}}, 'schema': {'default': <AuthTy...son_schema at 0x1069b7560>]}, 'ref': 'src.config.AuthType:4404265168', ...}, 'type': 'default'}, 'type': 'model-field'}
source = "Model 'ServiceAccountCredentials'"

    def _infer_discriminator_values_for_field(self, field: CoreSchemaField, source: str) -> list[str | int]:
        if field['type'] == 'computed-field':
            # This should never occur as a discriminator, as it is only relevant to serialization
            return []
        alias = field.get('validation_alias', self.discriminator)
        if not isinstance(alias, str):
            raise PydanticUserError(
                f'Alias {alias!r} is not supported in a discriminated union', code='discriminator-alias-type'
            )
        if self._discriminator_alias is None:
            self._discriminator_alias = alias
        elif self._discriminator_alias != alias:
            raise PydanticUserError(
                f'Aliases for discriminator {self.discriminator!r} must be the same '
                f'(got {alias}, {self._discriminator_alias})',
                code='discriminator-alias',
            )
>       return self._infer_discriminator_values_for_inner_schema(field['schema'], source)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:419: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
schema = {'default': <AuthType.SERVICE_ACCOUNT: 'service_account'>, 'schema': {'cls': <enum 'AuthType'>, 'members': [<AuthType....um_schema.<locals>.get_json_schema at 0x1069b7560>]}, 'ref': 'src.config.AuthType:4404265168', ...}, 'type': 'default'}
source = "Model 'ServiceAccountCredentials'"

    def _infer_discriminator_values_for_inner_schema(
        self, schema: core_schema.CoreSchema, source: str
    ) -> list[str | int]:
        """When inferring discriminator values for a field, we typically extract the expected values from a literal
        schema. This function does that, but also handles nested unions and defaults.
        """
        if schema['type'] == 'literal':
            return schema['expected']
    
        elif schema['type'] == 'union':
            # Generally when multiple values are allowed they should be placed in a single `Literal`, but
            # we add this case to handle the situation where a field is annotated as a `Union` of `Literal`s.
            # For example, this lets us handle `Union[Literal['key'], Union[Literal['Key'], Literal['KEY']]]`
            values: list[Any] = []
            for choice in schema['choices']:
                choice_schema = choice[0] if isinstance(choice, tuple) else choice
                choice_values = self._infer_discriminator_values_for_inner_schema(choice_schema, source)
                values.extend(choice_values)
            return values
    
        elif schema['type'] == 'default':
            # This will happen if the field has a default value; we ignore it while extracting the discriminator values
>           return self._infer_discriminator_values_for_inner_schema(schema['schema'], source)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:443: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
schema = {'cls': <enum 'AuthType'>, 'members': [<AuthType.SERVICE_ACCOUNT: 'service_account'>, <AuthType.OAUTH2: 'oauth2'>], 'm...n GenerateSchema._enum_schema.<locals>.get_json_schema at 0x1069b7560>]}, 'ref': 'src.config.AuthType:4404265168', ...}
source = "Model 'ServiceAccountCredentials'"

    def _infer_discriminator_values_for_inner_schema(
        self, schema: core_schema.CoreSchema, source: str
    ) -> list[str | int]:
        """When inferring discriminator values for a field, we typically extract the expected values from a literal
        schema. This function does that, but also handles nested unions and defaults.
        """
        if schema['type'] == 'literal':
            return schema['expected']
    
        elif schema['type'] == 'union':
            # Generally when multiple values are allowed they should be placed in a single `Literal`, but
            # we add this case to handle the situation where a field is annotated as a `Union` of `Literal`s.
            # For example, this lets us handle `Union[Literal['key'], Union[Literal['Key'], Literal['KEY']]]`
            values: list[Any] = []
            for choice in schema['choices']:
                choice_schema = choice[0] if isinstance(choice, tuple) else choice
                choice_values = self._infer_discriminator_values_for_inner_schema(choice_schema, source)
                values.extend(choice_values)
            return values
    
        elif schema['type'] == 'default':
            # This will happen if the field has a default value; we ignore it while extracting the discriminator values
            return self._infer_discriminator_values_for_inner_schema(schema['schema'], source)
    
        elif schema['type'] == 'function-after':
            # After validators don't affect the discriminator values
            return self._infer_discriminator_values_for_inner_schema(schema['schema'], source)
    
        elif schema['type'] in {'function-before', 'function-wrap', 'function-plain'}:
            validator_type = repr(schema['type'].split('-')[1])
            raise PydanticUserError(
                f'Cannot use a mode={validator_type} validator in the'
                f' discriminator field {self.discriminator!r} of {source}',
                code='discriminator-validator',
            )
    
        else:
>           raise PydanticUserError(
                f'{source} needs field {self.discriminator!r} to be of type `Literal`',
                code='discriminator-needs-literal',
            )
E           pydantic.errors.PydanticUserError: Model 'ServiceAccountCredentials' needs field 'auth_type' to be of type `Literal`
E           
E           For further information visit https://errors.pydantic.dev/2.12/u/discriminator-needs-literal

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:458: PydanticUserError
______________________ ERROR collecting test_discovery.py ______________________

    """
    Test schema discovery for Google Sheets connector.
    
    Tests:
    - Stream discovery
    - Schema generation from headers
    - Catalog format
    """
    
    import sys
    import os
    import pytest
    from unittest.mock import Mock, patch, MagicMock
    
    # Add src to path
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))
    
>   from connector import GoogleSheetsConnector

tests/test_discovery.py:18: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Main Google Sheets connector implementation.
    
    Provides the primary interface for connecting to Google Sheets,
    discovering available data streams, and reading data.
    """
    
    import json
    import logging
    import sys
    from dataclasses import dataclass
    from enum import Enum
    from typing import Any, Dict, Generator, Iterator, List, Optional, Union
    
    from src.auth import (
        GoogleSheetsAuthenticator,
        ServiceAccountAuth,
        OAuth2Auth,
        AuthenticationError,
        create_authenticator,
    )
    from src.client import (
        GoogleSheetsClient,
        GoogleSheetsAPIError,
        SpreadsheetNotFoundError,
        AccessDeniedError,
    )
>   from src.config import GoogleSheetsConfig

src/connector.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Google Sheets Source Connector
    
    A production-ready connector for extracting data from Google Sheets.
    Supports OAuth2 and Service Account authentication methods.
    """
    
    from src.auth import (
        GoogleSheetsAuthenticator,
        ServiceAccountAuth,
        OAuth2Auth,
        AuthenticationError,
    )
    from src.client import GoogleSheetsClient, GoogleSheetsAPIError
>   from src.config import (
        GoogleSheetsConfig,
        ServiceAccountCredentials,
        OAuth2Credentials,
    )

src/__init__.py:15: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Configuration models for Google Sheets connector using Pydantic.
    
    Provides validation and type safety for connector configuration.
    """
    
    import json
    import re
    from enum import Enum
    from typing import Any, Dict, List, Optional, Union
    
    from pydantic import BaseModel, Field, field_validator, model_validator
    
    
    class AuthType(str, Enum):
        """Supported authentication types."""
    
        SERVICE_ACCOUNT = "service_account"
        OAUTH2 = "oauth2"
    
    
    class ServiceAccountCredentials(BaseModel):
        """Configuration for Service Account authentication."""
    
        auth_type: AuthType = Field(
            default=AuthType.SERVICE_ACCOUNT,
            description="Authentication type identifier",
        )
        service_account_info: Optional[Union[str, Dict[str, Any]]] = Field(
            default=None,
            description="Service account JSON key as string or dictionary",
        )
        service_account_file: Optional[str] = Field(
            default=None,
            description="Path to service account JSON key file",
        )
    
        @model_validator(mode="after")
        def validate_credentials_source(self) -> "ServiceAccountCredentials":
            """Ensure at least one credential source is provided."""
            if not self.service_account_info and not self.service_account_file:
                raise ValueError(
                    "Must provide either service_account_info or service_account_file"
                )
            return self
    
        @field_validator("service_account_info", mode="before")
        @classmethod
        def parse_service_account_info(cls, v: Optional[Union[str, Dict]]) -> Optional[Dict]:
            """Parse service account info from string if needed."""
            if v is None:
                return None
            if isinstance(v, str):
                try:
                    return json.loads(v)
                except json.JSONDecodeError as e:
                    raise ValueError(f"Invalid JSON in service_account_info: {e}")
            return v
    
    
    class OAuth2Credentials(BaseModel):
        """Configuration for OAuth2 authentication."""
    
        auth_type: AuthType = Field(
            default=AuthType.OAUTH2,
            description="Authentication type identifier",
        )
        client_id: str = Field(
            ...,
            min_length=1,
            description="OAuth2 client ID",
        )
        client_secret: str = Field(
            ...,
            min_length=1,
            description="OAuth2 client secret",
        )
        refresh_token: str = Field(
            ...,
            min_length=1,
            description="OAuth2 refresh token",
        )
        access_token: Optional[str] = Field(
            default=None,
            description="Optional existing access token",
        )
    
    
    # Union type for credentials
    CredentialsConfig = Union[ServiceAccountCredentials, OAuth2Credentials]
    
    
    class StreamSelection(BaseModel):
        """Configuration for selecting which streams/sheets to sync."""
    
        sheet_names: Optional[List[str]] = Field(
            default=None,
            description="List of sheet names to sync. If None, all sheets are synced.",
        )
        exclude_sheets: Optional[List[str]] = Field(
            default=None,
            description="List of sheet names to exclude from sync.",
        )
    
    
>   class GoogleSheetsConfig(BaseModel):

src/config.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

mcs = <class 'pydantic._internal._model_construction.ModelMetaclass'>
cls_name = 'GoogleSheetsConfig', bases = (<class 'pydantic.main.BaseModel'>,)
namespace = {'__module__': 'src.config', '__qualname__': 'GoogleSheetsConfig', '__firstlineno__': 106, '__annotations__': {'spread...t 0x106c109a0>, '__static_attributes__': (), 'model_config': {}, '__class_vars__': set(), '__private_attributes__': {}}
__pydantic_generic_metadata__ = None, __pydantic_reset_parent_namespace__ = True
_create_model_module = None, kwargs = {}
raw_annotations = {'credentials': typing.Union[src.config.ServiceAccountCredentials, src.config.OAuth2Credentials], 'date_time_render_option': <class 'str'>, 'include_row_number': <class 'bool'>, 'requests_per_minute': <class 'int'>, ...}
base_field_names = set(), class_vars = set()

    def __new__(
        mcs,
        cls_name: str,
        bases: tuple[type[Any], ...],
        namespace: dict[str, Any],
        __pydantic_generic_metadata__: PydanticGenericMetadata | None = None,
        __pydantic_reset_parent_namespace__: bool = True,
        _create_model_module: str | None = None,
        **kwargs: Any,
    ) -> type:
        """Metaclass for creating Pydantic models.
    
        Args:
            cls_name: The name of the class to be created.
            bases: The base classes of the class to be created.
            namespace: The attribute dictionary of the class to be created.
            __pydantic_generic_metadata__: Metadata for generic models.
            __pydantic_reset_parent_namespace__: Reset parent namespace.
            _create_model_module: The module of the class to be created, if created by `create_model`.
            **kwargs: Catch-all for any other keyword arguments.
    
        Returns:
            The new class created by the metaclass.
        """
        # Note `ModelMetaclass` refers to `BaseModel`, but is also used to *create* `BaseModel`, so we rely on the fact
        # that `BaseModel` itself won't have any bases, but any subclass of it will, to determine whether the `__new__`
        # call we're in the middle of is for the `BaseModel` class.
        if bases:
            raw_annotations: dict[str, Any]
            if sys.version_info >= (3, 14):
                if (
                    '__annotations__' in namespace
                ):  # `from __future__ import annotations` was used in the model's module
                    raw_annotations = namespace['__annotations__']
                else:
                    # See https://docs.python.org/3.14/library/annotationlib.html#using-annotations-in-a-metaclass:
                    from annotationlib import Format, call_annotate_function, get_annotate_from_class_namespace
    
                    if annotate := get_annotate_from_class_namespace(namespace):
                        raw_annotations = call_annotate_function(annotate, format=Format.FORWARDREF)
                    else:
                        raw_annotations = {}
            else:
                raw_annotations = namespace.get('__annotations__', {})
    
            base_field_names, class_vars, base_private_attributes = mcs._collect_bases_data(bases)
    
            config_wrapper = ConfigWrapper.for_model(bases, namespace, raw_annotations, kwargs)
            namespace['model_config'] = config_wrapper.config_dict
            private_attributes = inspect_namespace(
                namespace, raw_annotations, config_wrapper.ignored_types, class_vars, base_field_names
            )
            if private_attributes or base_private_attributes:
                original_model_post_init = get_model_post_init(namespace, bases)
                if original_model_post_init is not None:
                    # if there are private_attributes and a model_post_init function, we handle both
    
                    @wraps(original_model_post_init)
                    def wrapped_model_post_init(self: BaseModel, context: Any, /) -> None:
                        """We need to both initialize private attributes and call the user-defined model_post_init
                        method.
                        """
                        init_private_attributes(self, context)
                        original_model_post_init(self, context)
    
                    namespace['model_post_init'] = wrapped_model_post_init
                else:
                    namespace['model_post_init'] = init_private_attributes
    
            namespace['__class_vars__'] = class_vars
            namespace['__private_attributes__'] = {**base_private_attributes, **private_attributes}
    
            cls = cast('type[BaseModel]', super().__new__(mcs, cls_name, bases, namespace, **kwargs))
            BaseModel_ = import_cached_base_model()
    
            mro = cls.__mro__
            if Generic in mro and mro.index(Generic) < mro.index(BaseModel_):
                warnings.warn(
                    GenericBeforeBaseModelWarning(
                        'Classes should inherit from `BaseModel` before generic classes (e.g. `typing.Generic[T]`) '
                        'for pydantic generics to work properly.'
                    ),
                    stacklevel=2,
                )
    
            cls.__pydantic_custom_init__ = not getattr(cls.__init__, '__pydantic_base_init__', False)
            cls.__pydantic_post_init__ = (
                None if cls.model_post_init is BaseModel_.model_post_init else 'model_post_init'
            )
    
            cls.__pydantic_setattr_handlers__ = {}
    
            cls.__pydantic_decorators__ = DecoratorInfos.build(cls)
            cls.__pydantic_decorators__.update_from_config(config_wrapper)
    
            # Use the getattr below to grab the __parameters__ from the `typing.Generic` parent class
            if __pydantic_generic_metadata__:
                cls.__pydantic_generic_metadata__ = __pydantic_generic_metadata__
            else:
                parent_parameters = getattr(cls, '__pydantic_generic_metadata__', {}).get('parameters', ())
                parameters = getattr(cls, '__parameters__', None) or parent_parameters
                if parameters and parent_parameters and not all(x in parameters for x in parent_parameters):
                    from ..root_model import RootModelRootType
    
                    missing_parameters = tuple(x for x in parameters if x not in parent_parameters)
                    if RootModelRootType in parent_parameters and RootModelRootType not in parameters:
                        # This is a special case where the user has subclassed `RootModel`, but has not parametrized
                        # RootModel with the generic type identifiers being used. Ex:
                        # class MyModel(RootModel, Generic[T]):
                        #    root: T
                        # Should instead just be:
                        # class MyModel(RootModel[T]):
                        #   root: T
                        parameters_str = ', '.join([x.__name__ for x in missing_parameters])
                        error_message = (
                            f'{cls.__name__} is a subclass of `RootModel`, but does not include the generic type identifier(s) '
                            f'{parameters_str} in its parameters. '
                            f'You should parametrize RootModel directly, e.g., `class {cls.__name__}(RootModel[{parameters_str}]): ...`.'
                        )
                    else:
                        combined_parameters = parent_parameters + missing_parameters
                        parameters_str = ', '.join([str(x) for x in combined_parameters])
                        generic_type_label = f'typing.Generic[{parameters_str}]'
                        error_message = (
                            f'All parameters must be present on typing.Generic;'
                            f' you should inherit from {generic_type_label}.'
                        )
                        if Generic not in bases:  # pragma: no cover
                            # We raise an error here not because it is desirable, but because some cases are mishandled.
                            # It would be nice to remove this error and still have things behave as expected, it's just
                            # challenging because we are using a custom `__class_getitem__` to parametrize generic models,
                            # and not returning a typing._GenericAlias from it.
                            bases_str = ', '.join([x.__name__ for x in bases] + [generic_type_label])
                            error_message += (
                                f' Note: `typing.Generic` must go last: `class {cls.__name__}({bases_str}): ...`)'
                            )
                    raise TypeError(error_message)
    
                cls.__pydantic_generic_metadata__ = {
                    'origin': None,
                    'args': (),
                    'parameters': parameters,
                }
    
            cls.__pydantic_complete__ = False  # Ensure this specific class gets completed
    
            # preserve `__set_name__` protocol defined in https://peps.python.org/pep-0487
            # for attributes not in `new_namespace` (e.g. private attributes)
            for name, obj in private_attributes.items():
                obj.__set_name__(cls, name)
    
            if __pydantic_reset_parent_namespace__:
                cls.__pydantic_parent_namespace__ = build_lenient_weakvaluedict(parent_frame_namespace())
            parent_namespace: dict[str, Any] | None = getattr(cls, '__pydantic_parent_namespace__', None)
            if isinstance(parent_namespace, dict):
                parent_namespace = unpack_lenient_weakvaluedict(parent_namespace)
    
            ns_resolver = NsResolver(parent_namespace=parent_namespace)
    
            set_model_fields(cls, config_wrapper=config_wrapper, ns_resolver=ns_resolver)
    
            # This is also set in `complete_model_class()`, after schema gen because they are recreated.
            # We set them here as well for backwards compatibility:
            cls.__pydantic_computed_fields__ = {
                k: v.info for k, v in cls.__pydantic_decorators__.computed_fields.items()
            }
    
            if config_wrapper.defer_build:
                set_model_mocks(cls)
            else:
                # Any operation that requires accessing the field infos instances should be put inside
                # `complete_model_class()`:
>               complete_model_class(
                    cls,
                    config_wrapper,
                    ns_resolver,
                    raise_errors=False,
                    create_model_module=_create_model_module,
                )

venv/lib/python3.13/site-packages/pydantic/_internal/_model_construction.py:255: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'src.config.GoogleSheetsConfig'>, config_wrapper = ConfigWrapper()
ns_resolver = <pydantic._internal._namespace_utils.NsResolver object at 0x10468d4f0>

    def complete_model_class(
        cls: type[BaseModel],
        config_wrapper: ConfigWrapper,
        ns_resolver: NsResolver,
        *,
        raise_errors: bool = True,
        call_on_complete_hook: bool = True,
        create_model_module: str | None = None,
    ) -> bool:
        """Finish building a model class.
    
        This logic must be called after class has been created since validation functions must be bound
        and `get_type_hints` requires a class object.
    
        Args:
            cls: BaseModel or dataclass.
            config_wrapper: The config wrapper instance.
            ns_resolver: The namespace resolver instance to use during schema building.
            raise_errors: Whether to raise errors.
            call_on_complete_hook: Whether to call the `__pydantic_on_complete__` hook.
            create_model_module: The module of the class to be created, if created by `create_model`.
    
        Returns:
            `True` if the model is successfully completed, else `False`.
    
        Raises:
            PydanticUndefinedAnnotation: If `PydanticUndefinedAnnotation` occurs in`__get_pydantic_core_schema__`
                and `raise_errors=True`.
        """
        typevars_map = get_model_typevars_map(cls)
    
        if not cls.__pydantic_fields_complete__:
            # Note: when coming from `ModelMetaclass.__new__()`, this results in fields being built twice.
            # We do so a second time here so that we can get the `NameError` for the specific undefined annotation.
            # Alternatively, we could let `GenerateSchema()` raise the error, but there are cases where incomplete
            # fields are inherited in `collect_model_fields()` and can actually have their annotation resolved in the
            # generate schema process. As we want to avoid having `__pydantic_fields_complete__` set to `False`
            # when `__pydantic_complete__` is `True`, we rebuild here:
            try:
                cls.__pydantic_fields__ = rebuild_model_fields(
                    cls,
                    config_wrapper=config_wrapper,
                    ns_resolver=ns_resolver,
                    typevars_map=typevars_map,
                )
            except NameError as e:
                exc = PydanticUndefinedAnnotation.from_name_error(e)
                set_model_mocks(cls, f'`{exc.name}`')
                if raise_errors:
                    raise exc from e
    
            if not raise_errors and not cls.__pydantic_fields_complete__:
                # No need to continue with schema gen, it is guaranteed to fail
                return False
    
            assert cls.__pydantic_fields_complete__
    
        gen_schema = GenerateSchema(
            config_wrapper,
            ns_resolver,
            typevars_map,
        )
    
        try:
>           schema = gen_schema.generate_schema(cls)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_model_construction.py:648: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x1069a7510>
obj = <class 'src.config.GoogleSheetsConfig'>

    def generate_schema(
        self,
        obj: Any,
    ) -> core_schema.CoreSchema:
        """Generate core schema.
    
        Args:
            obj: The object to generate core schema for.
    
        Returns:
            The generated core schema.
    
        Raises:
            PydanticUndefinedAnnotation:
                If it is not possible to evaluate forward reference.
            PydanticSchemaGenerationError:
                If it is not possible to generate pydantic-core schema.
            TypeError:
                - If `alias_generator` returns a disallowed type (must be str, AliasPath or AliasChoices).
                - If V1 style validator with `each_item=True` applied on a wrong field.
            PydanticUserError:
                - If `typing.TypedDict` is used instead of `typing_extensions.TypedDict` on Python < 3.12.
                - If `__modify_schema__` method is used instead of `__get_pydantic_json_schema__`.
        """
        schema = self._generate_schema_from_get_schema_method(obj, obj)
    
        if schema is None:
>           schema = self._generate_schema_inner(obj)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x1069a7510>
obj = <class 'src.config.GoogleSheetsConfig'>

    def _generate_schema_inner(self, obj: Any) -> core_schema.CoreSchema:
        if typing_objects.is_self(obj):
            obj = self._resolve_self_type(obj)
    
        if typing_objects.is_annotated(get_origin(obj)):
            return self._annotated_schema(obj)
    
        if isinstance(obj, dict):
            # we assume this is already a valid schema
            return obj  # type: ignore[return-value]
    
        if isinstance(obj, str):
            obj = ForwardRef(obj)
    
        if isinstance(obj, ForwardRef):
            return self.generate_schema(self._resolve_forward_ref(obj))
    
        BaseModel = import_cached_base_model()
    
        if lenient_issubclass(obj, BaseModel):
            with self.model_type_stack.push(obj):
>               return self._model_schema(obj)
                       ^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1023: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x1069a7510>
cls = <class 'src.config.GoogleSheetsConfig'>

    def _model_schema(self, cls: type[BaseModel]) -> core_schema.CoreSchema:
        """Generate schema for a Pydantic model."""
        BaseModel_ = import_cached_base_model()
    
        with self.defs.get_schema_or_ref(cls) as (model_ref, maybe_schema):
            if maybe_schema is not None:
                return maybe_schema
    
            schema = cls.__dict__.get('__pydantic_core_schema__')
            if schema is not None and not isinstance(schema, MockCoreSchema):
                if schema['type'] == 'definitions':
                    schema = self.defs.unpack_definitions(schema)
                ref = get_ref(schema)
                if ref:
                    return self.defs.create_definition_reference_schema(schema)
                else:
                    return schema
    
            config_wrapper = ConfigWrapper(cls.model_config, check=False)
    
            with self._config_wrapper_stack.push(config_wrapper), self._ns_resolver.push(cls):
                core_config = self._config_wrapper.core_config(title=cls.__name__)
    
                if cls.__pydantic_fields_complete__ or cls is BaseModel_:
                    fields = getattr(cls, '__pydantic_fields__', {})
                else:
                    if '__pydantic_fields__' not in cls.__dict__:
                        # This happens when we have a loop in the schema generation:
                        # class Base[T](BaseModel):
                        #     t: T
                        #
                        # class Other(BaseModel):
                        #     b: 'Base[Other]'
                        # When we build fields for `Other`, we evaluate the forward annotation.
                        # At this point, `Other` doesn't have the model fields set. We create
                        # `Base[Other]`; model fields are successfully built, and we try to generate
                        # a schema for `t: Other`. As `Other.__pydantic_fields__` aren't set, we abort.
                        raise PydanticUndefinedAnnotation(
                            name=cls.__name__,
                            message=f'Class {cls.__name__!r} is not defined',
                        )
                    try:
                        fields = rebuild_model_fields(
                            cls,
                            config_wrapper=self._config_wrapper,
                            ns_resolver=self._ns_resolver,
                            typevars_map=self._typevars_map or {},
                        )
                    except NameError as e:
                        raise PydanticUndefinedAnnotation.from_name_error(e) from e
    
                decorators = cls.__pydantic_decorators__
                computed_fields = decorators.computed_fields
                check_decorator_fields_exist(
                    chain(
                        decorators.field_validators.values(),
                        decorators.field_serializers.values(),
                        decorators.validators.values(),
                    ),
                    {*fields.keys(), *computed_fields.keys()},
                )
    
                model_validators = decorators.model_validators.values()
    
                extras_schema = None
                extras_keys_schema = None
                if core_config.get('extra_fields_behavior') == 'allow':
                    assert cls.__mro__[0] is cls
                    assert cls.__mro__[-1] is object
                    for candidate_cls in cls.__mro__[:-1]:
                        extras_annotation = getattr(candidate_cls, '__annotations__', {}).get(
                            '__pydantic_extra__', None
                        )
                        if extras_annotation is not None:
                            if isinstance(extras_annotation, str):
                                extras_annotation = _typing_extra.eval_type_backport(
                                    _typing_extra._make_forward_ref(
                                        extras_annotation, is_argument=False, is_class=True
                                    ),
                                    *self._types_namespace,
                                )
                            tp = get_origin(extras_annotation)
                            if tp not in DICT_TYPES:
                                raise PydanticSchemaGenerationError(
                                    'The type annotation for `__pydantic_extra__` must be `dict[str, ...]`'
                                )
                            extra_keys_type, extra_items_type = self._get_args_resolving_forward_refs(
                                extras_annotation,
                                required=True,
                            )
                            if extra_keys_type is not str:
                                extras_keys_schema = self.generate_schema(extra_keys_type)
                            if not typing_objects.is_any(extra_items_type):
                                extras_schema = self.generate_schema(extra_items_type)
                            if extras_keys_schema is not None or extras_schema is not None:
                                break
    
                generic_origin: type[BaseModel] | None = getattr(cls, '__pydantic_generic_metadata__', {}).get('origin')
    
                if cls.__pydantic_root_model__:
                    # FIXME: should the common field metadata be used here?
                    inner_schema, _ = self._common_field_schema('root', fields['root'], decorators)
                    inner_schema = apply_model_validators(inner_schema, model_validators, 'inner')
                    model_schema = core_schema.model_schema(
                        cls,
                        inner_schema,
                        generic_origin=generic_origin,
                        custom_init=getattr(cls, '__pydantic_custom_init__', None),
                        root_model=True,
                        post_init=getattr(cls, '__pydantic_post_init__', None),
                        config=core_config,
                        ref=model_ref,
                    )
                else:
                    fields_schema: core_schema.CoreSchema = core_schema.model_fields_schema(
>                       {k: self._generate_md_field_schema(k, v, decorators) for k, v in fields.items()},
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                        computed_fields=[
                            self._computed_field_schema(d, decorators.field_serializers)
                            for d in computed_fields.values()
                        ],
                        extras_schema=extras_schema,
                        extras_keys_schema=extras_keys_schema,
                        model_name=cls.__name__,
                    )

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:856: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x1069a7510>
name = 'credentials'
field_info = FieldInfo(annotation=Union[ServiceAccountCredentials, OAuth2Credentials], required=True, description='Authentication credentials', discriminator='auth_type')
decorators = DecoratorInfos(validators={}, field_validators={'extract_spreadsheet_id': Decorator(cls_ref='src.config.GoogleSheetsCo...cUndefined))}, root_validators={}, field_serializers={}, model_serializers={}, model_validators={}, computed_fields={})

    def _generate_md_field_schema(
        self,
        name: str,
        field_info: FieldInfo,
        decorators: DecoratorInfos,
    ) -> core_schema.ModelField:
        """Prepare a ModelField to represent a model field."""
>       schema, metadata = self._common_field_schema(name, field_info, decorators)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x1069a7510>
name = 'credentials'
field_info = FieldInfo(annotation=Union[ServiceAccountCredentials, OAuth2Credentials], required=True, description='Authentication credentials', discriminator='auth_type')
decorators = DecoratorInfos(validators={}, field_validators={'extract_spreadsheet_id': Decorator(cls_ref='src.config.GoogleSheetsCo...cUndefined))}, root_validators={}, field_serializers={}, model_serializers={}, model_validators={}, computed_fields={})

    def _common_field_schema(  # C901
        self, name: str, field_info: FieldInfo, decorators: DecoratorInfos
    ) -> tuple[CoreSchema, dict[str, Any]]:
        source_type, annotations = field_info.annotation, field_info.metadata
    
        def set_discriminator(schema: CoreSchema) -> CoreSchema:
            schema = self._apply_discriminator_to_union(schema, field_info.discriminator)
            return schema
    
        # Convert `@field_validator` decorators to `Before/After/Plain/WrapValidator` instances:
        validators_from_decorators = [
            _mode_to_validator[decorator.info.mode]._from_decorator(decorator)
            for decorator in filter_field_decorator_info_by_field(decorators.field_validators.values(), name)
        ]
    
        with self.field_name_stack.push(name):
            if field_info.discriminator is not None:
>               schema = self._apply_annotations(
                    source_type, annotations + validators_from_decorators, transform_inner_schema=set_discriminator
                )

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1278: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x1069a7510>
source_type = typing.Union[src.config.ServiceAccountCredentials, src.config.OAuth2Credentials]
annotations = []
transform_inner_schema = <function GenerateSchema._common_field_schema.<locals>.set_discriminator at 0x106c11940>
check_unsupported_field_info_attributes = True

    def _apply_annotations(
        self,
        source_type: Any,
        annotations: list[Any],
        transform_inner_schema: Callable[[CoreSchema], CoreSchema] = lambda x: x,
        check_unsupported_field_info_attributes: bool = True,
    ) -> CoreSchema:
        """Apply arguments from `Annotated` or from `FieldInfo` to a schema.
    
        This gets called by `GenerateSchema._annotated_schema` but differs from it in that it does
        not expect `source_type` to be an `Annotated` object, it expects it to be  the first argument of that
        (in other words, `GenerateSchema._annotated_schema` just unpacks `Annotated`, this process it).
        """
        annotations = list(_known_annotated_metadata.expand_grouped_metadata(annotations))
    
        pydantic_js_annotation_functions: list[GetJsonSchemaFunction] = []
    
        def inner_handler(obj: Any) -> CoreSchema:
            schema = self._generate_schema_from_get_schema_method(obj, source_type)
    
            if schema is None:
                schema = self._generate_schema_inner(obj)
    
            metadata_js_function = _extract_get_pydantic_json_schema(obj)
            if metadata_js_function is not None:
                metadata_schema = resolve_original_schema(schema, self.defs)
                if metadata_schema is not None:
                    self._add_js_function(metadata_schema, metadata_js_function)
            return transform_inner_schema(schema)
    
        get_inner_schema = CallbackGetCoreSchemaHandler(inner_handler, self)
    
        for annotation in annotations:
            if annotation is None:
                continue
            get_inner_schema = self._get_wrapped_inner_schema(
                get_inner_schema,
                annotation,
                pydantic_js_annotation_functions,
                check_unsupported_field_info_attributes=check_unsupported_field_info_attributes,
            )
    
>       schema = get_inner_schema(source_type)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2227: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._schema_generation_shared.CallbackGetCoreSchemaHandler object at 0x106b03a10>
source_type = typing.Union[src.config.ServiceAccountCredentials, src.config.OAuth2Credentials]

    def __call__(self, source_type: Any, /) -> core_schema.CoreSchema:
>       schema = self._handler(source_type)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_schema_generation_shared.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = typing.Union[src.config.ServiceAccountCredentials, src.config.OAuth2Credentials]

    def inner_handler(obj: Any) -> CoreSchema:
        schema = self._generate_schema_from_get_schema_method(obj, source_type)
    
        if schema is None:
            schema = self._generate_schema_inner(obj)
    
        metadata_js_function = _extract_get_pydantic_json_schema(obj)
        if metadata_js_function is not None:
            metadata_schema = resolve_original_schema(schema, self.defs)
            if metadata_schema is not None:
                self._add_js_function(metadata_schema, metadata_js_function)
>       return transform_inner_schema(schema)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2213: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

schema = {'choices': [{'schema_ref': 'src.config.ServiceAccountCredentials:4386272368', 'type': 'definition-ref'}, {'schema_ref': 'src.config.OAuth2Credentials:4359162432', 'type': 'definition-ref'}], 'type': 'union'}

    def set_discriminator(schema: CoreSchema) -> CoreSchema:
>       schema = self._apply_discriminator_to_union(schema, field_info.discriminator)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x1069a7510>
schema = {'choices': [{'schema_ref': 'src.config.ServiceAccountCredentials:4386272368', 'type': 'definition-ref'}, {'schema_ref': 'src.config.OAuth2Credentials:4359162432', 'type': 'definition-ref'}], 'type': 'union'}
discriminator = 'auth_type'

    def _apply_discriminator_to_union(
        self, schema: CoreSchema, discriminator: str | Discriminator | None
    ) -> CoreSchema:
        if discriminator is None:
            return schema
        try:
>           return _discriminated_union.apply_discriminator(
                schema,
                discriminator,
                self.defs._definitions,
            )

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:675: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

schema = {'choices': [{'schema_ref': 'src.config.ServiceAccountCredentials:4386272368', 'type': 'definition-ref'}, {'schema_ref': 'src.config.OAuth2Credentials:4359162432', 'type': 'definition-ref'}], 'type': 'union'}
discriminator = 'auth_type'
definitions = {'src.config.OAuth2Credentials:4359162432': {'cls': <class 'src.config.OAuth2Credentials'>, 'config': {'title': 'OAuth...Credentials'>, 'config': {'title': 'ServiceAccountCredentials'}, 'custom_init': False, 'root_model': False, ...}, ...}}

    def apply_discriminator(
        schema: core_schema.CoreSchema,
        discriminator: str | Discriminator,
        definitions: dict[str, core_schema.CoreSchema] | None = None,
    ) -> core_schema.CoreSchema:
        """Applies the discriminator and returns a new core schema.
    
        Args:
            schema: The input schema.
            discriminator: The name of the field which will serve as the discriminator.
            definitions: A mapping of schema ref to schema.
    
        Returns:
            The new core schema.
    
        Raises:
            TypeError:
                - If `discriminator` is used with invalid union variant.
                - If `discriminator` is used with `Union` type with one variant.
                - If `discriminator` value mapped to multiple choices.
            MissingDefinitionForUnionRef:
                If the definition for ref is missing.
            PydanticUserError:
                - If a model in union doesn't have a discriminator field.
                - If discriminator field has a non-string alias.
                - If discriminator fields have different aliases.
                - If discriminator field not of type `Literal`.
        """
        from ..types import Discriminator
    
        if isinstance(discriminator, Discriminator):
            if isinstance(discriminator.discriminator, str):
                discriminator = discriminator.discriminator
            else:
                return discriminator._convert_schema(schema)
    
>       return _ApplyInferredDiscriminator(discriminator, definitions or {}).apply(schema)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
schema = {'choices': [{'schema_ref': 'src.config.ServiceAccountCredentials:4386272368', 'type': 'definition-ref'}, {'schema_ref': 'src.config.OAuth2Credentials:4359162432', 'type': 'definition-ref'}], 'type': 'union'}

    def apply(self, schema: core_schema.CoreSchema) -> core_schema.CoreSchema:
        """Return a new CoreSchema based on `schema` that uses a tagged-union with the discriminator provided
        to this class.
    
        Args:
            schema: The input schema.
    
        Returns:
            The new core schema.
    
        Raises:
            TypeError:
                - If `discriminator` is used with invalid union variant.
                - If `discriminator` is used with `Union` type with one variant.
                - If `discriminator` value mapped to multiple choices.
            ValueError:
                If the definition for ref is missing.
            PydanticUserError:
                - If a model in union doesn't have a discriminator field.
                - If discriminator field has a non-string alias.
                - If discriminator fields have different aliases.
                - If discriminator field not of type `Literal`.
        """
        assert not self._used
>       schema = self._apply_to_root(schema)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:164: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
schema = {'choices': [{'schema_ref': 'src.config.ServiceAccountCredentials:4386272368', 'type': 'definition-ref'}, {'schema_ref': 'src.config.OAuth2Credentials:4359162432', 'type': 'definition-ref'}], 'type': 'union'}

    def _apply_to_root(self, schema: core_schema.CoreSchema) -> core_schema.CoreSchema:
        """This method handles the outer-most stage of recursion over the input schema:
        unwrapping nullable or definitions schemas, and calling the `_handle_choice`
        method iteratively on the choices extracted (recursively) from the possibly-wrapped union.
        """
        if schema['type'] == 'nullable':
            self._is_nullable = True
            wrapped = self._apply_to_root(schema['schema'])
            nullable_wrapper = schema.copy()
            nullable_wrapper['schema'] = wrapped
            return nullable_wrapper
    
        if schema['type'] == 'definitions':
            wrapped = self._apply_to_root(schema['schema'])
            definitions_wrapper = schema.copy()
            definitions_wrapper['schema'] = wrapped
            return definitions_wrapper
    
        if schema['type'] != 'union':
            # If the schema is not a union, it probably means it just had a single member and
            # was flattened by pydantic_core.
            # However, it still may make sense to apply the discriminator to this schema,
            # as a way to get discriminated-union-style error messages, so we allow this here.
            schema = core_schema.union_schema([schema])
    
        # Reverse the choices list before extending the stack so that they get handled in the order they occur
        choices_schemas = [v[0] if isinstance(v, tuple) else v for v in schema['choices'][::-1]]
        self._choices_to_handle.extend(choices_schemas)
        while self._choices_to_handle:
            choice = self._choices_to_handle.pop()
>           self._handle_choice(choice)

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
choice = {'schema_ref': 'src.config.ServiceAccountCredentials:4386272368', 'type': 'definition-ref'}

    def _handle_choice(self, choice: core_schema.CoreSchema) -> None:
        """This method handles the "middle" stage of recursion over the input schema.
        Specifically, it is responsible for handling each choice of the outermost union
        (and any "coalesced" choices obtained from inner unions).
    
        Here, "handling" entails:
        * Coalescing nested unions and compatible tagged-unions
        * Tracking the presence of 'none' and 'nullable' schemas occurring as choices
        * Validating that each allowed discriminator value maps to a unique choice
        * Updating the _tagged_union_choices mapping that will ultimately be used to build the TaggedUnionSchema.
        """
        if choice['type'] == 'definition-ref':
            if choice['schema_ref'] not in self.definitions:
                raise MissingDefinitionForUnionRef(choice['schema_ref'])
    
        if choice['type'] == 'none':
            self._should_be_nullable = True
        elif choice['type'] == 'definitions':
            self._handle_choice(choice['schema'])
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            self._handle_choice(choice['schema'])  # unwrap the nullable schema
        elif choice['type'] == 'union':
            # Reverse the choices list before extending the stack so that they get handled in the order they occur
            choices_schemas = [v[0] if isinstance(v, tuple) else v for v in choice['choices'][::-1]]
            self._choices_to_handle.extend(choices_schemas)
        elif choice['type'] not in {
            'model',
            'typed-dict',
            'tagged-union',
            'lax-or-strict',
            'dataclass',
            'dataclass-args',
            'definition-ref',
        } and not _core_utils.is_function_with_inner_schema(choice):
            # We should eventually handle 'definition-ref' as well
            err_str = f'The core schema type {choice["type"]!r} is not a valid discriminated union variant.'
            if choice['type'] == 'list':
                err_str += (
                    ' If you are making use of a list of union types, make sure the discriminator is applied to the '
                    'union type and not the list (e.g. `list[Annotated[<T> | <U>, Field(discriminator=...)]]`).'
                )
            raise TypeError(err_str)
        else:
            if choice['type'] == 'tagged-union' and self._is_discriminator_shared(choice):
                # In this case, this inner tagged-union is compatible with the outer tagged-union,
                # and its choices can be coalesced into the outer TaggedUnionSchema.
                subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
                # Reverse the choices list before extending the stack so that they get handled in the order they occur
                self._choices_to_handle.extend(subchoices[::-1])
                return
    
>           inferred_discriminator_values = self._infer_discriminator_values_for_choice(choice, source_name=None)
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:278: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
choice = {'schema_ref': 'src.config.ServiceAccountCredentials:4386272368', 'type': 'definition-ref'}
source_name = None

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif choice['type'] == 'lax-or-strict':
            return sorted(
                set(
                    self._infer_discriminator_values_for_choice(choice['lax_schema'], source_name=None)
                    + self._infer_discriminator_values_for_choice(choice['strict_schema'], source_name=None)
                )
            )
    
        elif choice['type'] == 'tagged-union':
            values: list[str | int] = []
            # Ignore str/int "choices" since these are just references to other choices
            subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
            for subchoice in subchoices:
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'union':
            values = []
            for subchoice in choice['choices']:
                subchoice_schema = subchoice[0] if isinstance(subchoice, tuple) else subchoice
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice_schema, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=None)
    
        elif choice['type'] == 'model':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'dataclass':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'model-fields':
            return self._infer_discriminator_values_for_model_choice(choice, source_name=source_name)
    
        elif choice['type'] == 'dataclass-args':
            return self._infer_discriminator_values_for_dataclass_choice(choice, source_name=source_name)
    
        elif choice['type'] == 'typed-dict':
            return self._infer_discriminator_values_for_typed_dict_choice(choice, source_name=source_name)
    
        elif choice['type'] == 'definition-ref':
            schema_ref = choice['schema_ref']
            if schema_ref not in self.definitions:
                raise MissingDefinitionForUnionRef(schema_ref)
>           return self._infer_discriminator_values_for_choice(self.definitions[schema_ref], source_name=source_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
choice = {'function': {'function': <function ServiceAccountCredentials.validate_credentials_source at 0x106c10900>, 'type': 'no...tCredentials'>, 'config': {'title': 'ServiceAccountCredentials'}, 'custom_init': False, 'root_model': False, ...}, ...}
source_name = None

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
>           return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:304: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
choice = {'cls': <class 'src.config.ServiceAccountCredentials'>, 'config': {'title': 'ServiceAccountCredentials'}, 'custom_init': False, 'root_model': False, ...}
source_name = None

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif choice['type'] == 'lax-or-strict':
            return sorted(
                set(
                    self._infer_discriminator_values_for_choice(choice['lax_schema'], source_name=None)
                    + self._infer_discriminator_values_for_choice(choice['strict_schema'], source_name=None)
                )
            )
    
        elif choice['type'] == 'tagged-union':
            values: list[str | int] = []
            # Ignore str/int "choices" since these are just references to other choices
            subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
            for subchoice in subchoices:
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'union':
            values = []
            for subchoice in choice['choices']:
                subchoice_schema = subchoice[0] if isinstance(subchoice, tuple) else subchoice
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice_schema, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=None)
    
        elif choice['type'] == 'model':
>           return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
choice = {'computed_fields': [], 'fields': {'auth_type': {'metadata': {'pydantic_js_updates': {'description': 'Authentication t...fore'}, 'type': 'default'}, 'type': 'model-field'}}, 'model_name': 'ServiceAccountCredentials', 'type': 'model-fields'}
source_name = 'ServiceAccountCredentials'

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif choice['type'] == 'lax-or-strict':
            return sorted(
                set(
                    self._infer_discriminator_values_for_choice(choice['lax_schema'], source_name=None)
                    + self._infer_discriminator_values_for_choice(choice['strict_schema'], source_name=None)
                )
            )
    
        elif choice['type'] == 'tagged-union':
            values: list[str | int] = []
            # Ignore str/int "choices" since these are just references to other choices
            subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
            for subchoice in subchoices:
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'union':
            values = []
            for subchoice in choice['choices']:
                subchoice_schema = subchoice[0] if isinstance(subchoice, tuple) else subchoice
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice_schema, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=None)
    
        elif choice['type'] == 'model':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'dataclass':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'model-fields':
>           return self._infer_discriminator_values_for_model_choice(choice, source_name=source_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:342: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
choice = {'computed_fields': [], 'fields': {'auth_type': {'metadata': {'pydantic_js_updates': {'description': 'Authentication t...fore'}, 'type': 'default'}, 'type': 'model-field'}}, 'model_name': 'ServiceAccountCredentials', 'type': 'model-fields'}
source_name = 'ServiceAccountCredentials'

    def _infer_discriminator_values_for_model_choice(
        self, choice: core_schema.ModelFieldsSchema, source_name: str | None = None
    ) -> list[str | int]:
        source = 'ModelFields' if source_name is None else f'Model {source_name!r}'
        field = choice['fields'].get(self.discriminator)
        if field is None:
            raise PydanticUserError(
                f'{source} needs a discriminator field for key {self.discriminator!r}', code='discriminator-no-field'
            )
>       return self._infer_discriminator_values_for_field(field, source)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
field = {'metadata': {'pydantic_js_updates': {'description': 'Authentication type identifier'}}, 'schema': {'default': <AuthTy...son_schema at 0x106c12f20>]}, 'ref': 'src.config.AuthType:4386277584', ...}, 'type': 'default'}, 'type': 'model-field'}
source = "Model 'ServiceAccountCredentials'"

    def _infer_discriminator_values_for_field(self, field: CoreSchemaField, source: str) -> list[str | int]:
        if field['type'] == 'computed-field':
            # This should never occur as a discriminator, as it is only relevant to serialization
            return []
        alias = field.get('validation_alias', self.discriminator)
        if not isinstance(alias, str):
            raise PydanticUserError(
                f'Alias {alias!r} is not supported in a discriminated union', code='discriminator-alias-type'
            )
        if self._discriminator_alias is None:
            self._discriminator_alias = alias
        elif self._discriminator_alias != alias:
            raise PydanticUserError(
                f'Aliases for discriminator {self.discriminator!r} must be the same '
                f'(got {alias}, {self._discriminator_alias})',
                code='discriminator-alias',
            )
>       return self._infer_discriminator_values_for_inner_schema(field['schema'], source)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:419: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
schema = {'default': <AuthType.SERVICE_ACCOUNT: 'service_account'>, 'schema': {'cls': <enum 'AuthType'>, 'members': [<AuthType....um_schema.<locals>.get_json_schema at 0x106c12f20>]}, 'ref': 'src.config.AuthType:4386277584', ...}, 'type': 'default'}
source = "Model 'ServiceAccountCredentials'"

    def _infer_discriminator_values_for_inner_schema(
        self, schema: core_schema.CoreSchema, source: str
    ) -> list[str | int]:
        """When inferring discriminator values for a field, we typically extract the expected values from a literal
        schema. This function does that, but also handles nested unions and defaults.
        """
        if schema['type'] == 'literal':
            return schema['expected']
    
        elif schema['type'] == 'union':
            # Generally when multiple values are allowed they should be placed in a single `Literal`, but
            # we add this case to handle the situation where a field is annotated as a `Union` of `Literal`s.
            # For example, this lets us handle `Union[Literal['key'], Union[Literal['Key'], Literal['KEY']]]`
            values: list[Any] = []
            for choice in schema['choices']:
                choice_schema = choice[0] if isinstance(choice, tuple) else choice
                choice_values = self._infer_discriminator_values_for_inner_schema(choice_schema, source)
                values.extend(choice_values)
            return values
    
        elif schema['type'] == 'default':
            # This will happen if the field has a default value; we ignore it while extracting the discriminator values
>           return self._infer_discriminator_values_for_inner_schema(schema['schema'], source)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:443: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10694a710>
schema = {'cls': <enum 'AuthType'>, 'members': [<AuthType.SERVICE_ACCOUNT: 'service_account'>, <AuthType.OAUTH2: 'oauth2'>], 'm...n GenerateSchema._enum_schema.<locals>.get_json_schema at 0x106c12f20>]}, 'ref': 'src.config.AuthType:4386277584', ...}
source = "Model 'ServiceAccountCredentials'"

    def _infer_discriminator_values_for_inner_schema(
        self, schema: core_schema.CoreSchema, source: str
    ) -> list[str | int]:
        """When inferring discriminator values for a field, we typically extract the expected values from a literal
        schema. This function does that, but also handles nested unions and defaults.
        """
        if schema['type'] == 'literal':
            return schema['expected']
    
        elif schema['type'] == 'union':
            # Generally when multiple values are allowed they should be placed in a single `Literal`, but
            # we add this case to handle the situation where a field is annotated as a `Union` of `Literal`s.
            # For example, this lets us handle `Union[Literal['key'], Union[Literal['Key'], Literal['KEY']]]`
            values: list[Any] = []
            for choice in schema['choices']:
                choice_schema = choice[0] if isinstance(choice, tuple) else choice
                choice_values = self._infer_discriminator_values_for_inner_schema(choice_schema, source)
                values.extend(choice_values)
            return values
    
        elif schema['type'] == 'default':
            # This will happen if the field has a default value; we ignore it while extracting the discriminator values
            return self._infer_discriminator_values_for_inner_schema(schema['schema'], source)
    
        elif schema['type'] == 'function-after':
            # After validators don't affect the discriminator values
            return self._infer_discriminator_values_for_inner_schema(schema['schema'], source)
    
        elif schema['type'] in {'function-before', 'function-wrap', 'function-plain'}:
            validator_type = repr(schema['type'].split('-')[1])
            raise PydanticUserError(
                f'Cannot use a mode={validator_type} validator in the'
                f' discriminator field {self.discriminator!r} of {source}',
                code='discriminator-validator',
            )
    
        else:
>           raise PydanticUserError(
                f'{source} needs field {self.discriminator!r} to be of type `Literal`',
                code='discriminator-needs-literal',
            )
E           pydantic.errors.PydanticUserError: Model 'ServiceAccountCredentials' needs field 'auth_type' to be of type `Literal`
E           
E           For further information visit https://errors.pydantic.dev/2.12/u/discriminator-needs-literal

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:458: PydanticUserError
________________________ ERROR collecting test_read.py _________________________

    """
    Test data reading for Google Sheets connector.
    
    Tests:
    - Reading records from sheets
    - Record format and structure
    - Row-to-record conversion
    - Batch processing
    """
    
    import sys
    import os
    import pytest
    from unittest.mock import Mock, patch, MagicMock
    
    # Add src to path
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))
    
>   from connector import GoogleSheetsConnector, SyncResult, ConnectorStatus

tests/test_read.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Main Google Sheets connector implementation.
    
    Provides the primary interface for connecting to Google Sheets,
    discovering available data streams, and reading data.
    """
    
    import json
    import logging
    import sys
    from dataclasses import dataclass
    from enum import Enum
    from typing import Any, Dict, Generator, Iterator, List, Optional, Union
    
    from src.auth import (
        GoogleSheetsAuthenticator,
        ServiceAccountAuth,
        OAuth2Auth,
        AuthenticationError,
        create_authenticator,
    )
    from src.client import (
        GoogleSheetsClient,
        GoogleSheetsAPIError,
        SpreadsheetNotFoundError,
        AccessDeniedError,
    )
>   from src.config import GoogleSheetsConfig

src/connector.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Google Sheets Source Connector
    
    A production-ready connector for extracting data from Google Sheets.
    Supports OAuth2 and Service Account authentication methods.
    """
    
    from src.auth import (
        GoogleSheetsAuthenticator,
        ServiceAccountAuth,
        OAuth2Auth,
        AuthenticationError,
    )
    from src.client import GoogleSheetsClient, GoogleSheetsAPIError
>   from src.config import (
        GoogleSheetsConfig,
        ServiceAccountCredentials,
        OAuth2Credentials,
    )

src/__init__.py:15: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Configuration models for Google Sheets connector using Pydantic.
    
    Provides validation and type safety for connector configuration.
    """
    
    import json
    import re
    from enum import Enum
    from typing import Any, Dict, List, Optional, Union
    
    from pydantic import BaseModel, Field, field_validator, model_validator
    
    
    class AuthType(str, Enum):
        """Supported authentication types."""
    
        SERVICE_ACCOUNT = "service_account"
        OAUTH2 = "oauth2"
    
    
    class ServiceAccountCredentials(BaseModel):
        """Configuration for Service Account authentication."""
    
        auth_type: AuthType = Field(
            default=AuthType.SERVICE_ACCOUNT,
            description="Authentication type identifier",
        )
        service_account_info: Optional[Union[str, Dict[str, Any]]] = Field(
            default=None,
            description="Service account JSON key as string or dictionary",
        )
        service_account_file: Optional[str] = Field(
            default=None,
            description="Path to service account JSON key file",
        )
    
        @model_validator(mode="after")
        def validate_credentials_source(self) -> "ServiceAccountCredentials":
            """Ensure at least one credential source is provided."""
            if not self.service_account_info and not self.service_account_file:
                raise ValueError(
                    "Must provide either service_account_info or service_account_file"
                )
            return self
    
        @field_validator("service_account_info", mode="before")
        @classmethod
        def parse_service_account_info(cls, v: Optional[Union[str, Dict]]) -> Optional[Dict]:
            """Parse service account info from string if needed."""
            if v is None:
                return None
            if isinstance(v, str):
                try:
                    return json.loads(v)
                except json.JSONDecodeError as e:
                    raise ValueError(f"Invalid JSON in service_account_info: {e}")
            return v
    
    
    class OAuth2Credentials(BaseModel):
        """Configuration for OAuth2 authentication."""
    
        auth_type: AuthType = Field(
            default=AuthType.OAUTH2,
            description="Authentication type identifier",
        )
        client_id: str = Field(
            ...,
            min_length=1,
            description="OAuth2 client ID",
        )
        client_secret: str = Field(
            ...,
            min_length=1,
            description="OAuth2 client secret",
        )
        refresh_token: str = Field(
            ...,
            min_length=1,
            description="OAuth2 refresh token",
        )
        access_token: Optional[str] = Field(
            default=None,
            description="Optional existing access token",
        )
    
    
    # Union type for credentials
    CredentialsConfig = Union[ServiceAccountCredentials, OAuth2Credentials]
    
    
    class StreamSelection(BaseModel):
        """Configuration for selecting which streams/sheets to sync."""
    
        sheet_names: Optional[List[str]] = Field(
            default=None,
            description="List of sheet names to sync. If None, all sheets are synced.",
        )
        exclude_sheets: Optional[List[str]] = Field(
            default=None,
            description="List of sheet names to exclude from sync.",
        )
    
    
>   class GoogleSheetsConfig(BaseModel):

src/config.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

mcs = <class 'pydantic._internal._model_construction.ModelMetaclass'>
cls_name = 'GoogleSheetsConfig', bases = (<class 'pydantic.main.BaseModel'>,)
namespace = {'__module__': 'src.config', '__qualname__': 'GoogleSheetsConfig', '__firstlineno__': 106, '__annotations__': {'spread...t 0x106b704a0>, '__static_attributes__': (), 'model_config': {}, '__class_vars__': set(), '__private_attributes__': {}}
__pydantic_generic_metadata__ = None, __pydantic_reset_parent_namespace__ = True
_create_model_module = None, kwargs = {}
raw_annotations = {'credentials': typing.Union[src.config.ServiceAccountCredentials, src.config.OAuth2Credentials], 'date_time_render_option': <class 'str'>, 'include_row_number': <class 'bool'>, 'requests_per_minute': <class 'int'>, ...}
base_field_names = set(), class_vars = set()

    def __new__(
        mcs,
        cls_name: str,
        bases: tuple[type[Any], ...],
        namespace: dict[str, Any],
        __pydantic_generic_metadata__: PydanticGenericMetadata | None = None,
        __pydantic_reset_parent_namespace__: bool = True,
        _create_model_module: str | None = None,
        **kwargs: Any,
    ) -> type:
        """Metaclass for creating Pydantic models.
    
        Args:
            cls_name: The name of the class to be created.
            bases: The base classes of the class to be created.
            namespace: The attribute dictionary of the class to be created.
            __pydantic_generic_metadata__: Metadata for generic models.
            __pydantic_reset_parent_namespace__: Reset parent namespace.
            _create_model_module: The module of the class to be created, if created by `create_model`.
            **kwargs: Catch-all for any other keyword arguments.
    
        Returns:
            The new class created by the metaclass.
        """
        # Note `ModelMetaclass` refers to `BaseModel`, but is also used to *create* `BaseModel`, so we rely on the fact
        # that `BaseModel` itself won't have any bases, but any subclass of it will, to determine whether the `__new__`
        # call we're in the middle of is for the `BaseModel` class.
        if bases:
            raw_annotations: dict[str, Any]
            if sys.version_info >= (3, 14):
                if (
                    '__annotations__' in namespace
                ):  # `from __future__ import annotations` was used in the model's module
                    raw_annotations = namespace['__annotations__']
                else:
                    # See https://docs.python.org/3.14/library/annotationlib.html#using-annotations-in-a-metaclass:
                    from annotationlib import Format, call_annotate_function, get_annotate_from_class_namespace
    
                    if annotate := get_annotate_from_class_namespace(namespace):
                        raw_annotations = call_annotate_function(annotate, format=Format.FORWARDREF)
                    else:
                        raw_annotations = {}
            else:
                raw_annotations = namespace.get('__annotations__', {})
    
            base_field_names, class_vars, base_private_attributes = mcs._collect_bases_data(bases)
    
            config_wrapper = ConfigWrapper.for_model(bases, namespace, raw_annotations, kwargs)
            namespace['model_config'] = config_wrapper.config_dict
            private_attributes = inspect_namespace(
                namespace, raw_annotations, config_wrapper.ignored_types, class_vars, base_field_names
            )
            if private_attributes or base_private_attributes:
                original_model_post_init = get_model_post_init(namespace, bases)
                if original_model_post_init is not None:
                    # if there are private_attributes and a model_post_init function, we handle both
    
                    @wraps(original_model_post_init)
                    def wrapped_model_post_init(self: BaseModel, context: Any, /) -> None:
                        """We need to both initialize private attributes and call the user-defined model_post_init
                        method.
                        """
                        init_private_attributes(self, context)
                        original_model_post_init(self, context)
    
                    namespace['model_post_init'] = wrapped_model_post_init
                else:
                    namespace['model_post_init'] = init_private_attributes
    
            namespace['__class_vars__'] = class_vars
            namespace['__private_attributes__'] = {**base_private_attributes, **private_attributes}
    
            cls = cast('type[BaseModel]', super().__new__(mcs, cls_name, bases, namespace, **kwargs))
            BaseModel_ = import_cached_base_model()
    
            mro = cls.__mro__
            if Generic in mro and mro.index(Generic) < mro.index(BaseModel_):
                warnings.warn(
                    GenericBeforeBaseModelWarning(
                        'Classes should inherit from `BaseModel` before generic classes (e.g. `typing.Generic[T]`) '
                        'for pydantic generics to work properly.'
                    ),
                    stacklevel=2,
                )
    
            cls.__pydantic_custom_init__ = not getattr(cls.__init__, '__pydantic_base_init__', False)
            cls.__pydantic_post_init__ = (
                None if cls.model_post_init is BaseModel_.model_post_init else 'model_post_init'
            )
    
            cls.__pydantic_setattr_handlers__ = {}
    
            cls.__pydantic_decorators__ = DecoratorInfos.build(cls)
            cls.__pydantic_decorators__.update_from_config(config_wrapper)
    
            # Use the getattr below to grab the __parameters__ from the `typing.Generic` parent class
            if __pydantic_generic_metadata__:
                cls.__pydantic_generic_metadata__ = __pydantic_generic_metadata__
            else:
                parent_parameters = getattr(cls, '__pydantic_generic_metadata__', {}).get('parameters', ())
                parameters = getattr(cls, '__parameters__', None) or parent_parameters
                if parameters and parent_parameters and not all(x in parameters for x in parent_parameters):
                    from ..root_model import RootModelRootType
    
                    missing_parameters = tuple(x for x in parameters if x not in parent_parameters)
                    if RootModelRootType in parent_parameters and RootModelRootType not in parameters:
                        # This is a special case where the user has subclassed `RootModel`, but has not parametrized
                        # RootModel with the generic type identifiers being used. Ex:
                        # class MyModel(RootModel, Generic[T]):
                        #    root: T
                        # Should instead just be:
                        # class MyModel(RootModel[T]):
                        #   root: T
                        parameters_str = ', '.join([x.__name__ for x in missing_parameters])
                        error_message = (
                            f'{cls.__name__} is a subclass of `RootModel`, but does not include the generic type identifier(s) '
                            f'{parameters_str} in its parameters. '
                            f'You should parametrize RootModel directly, e.g., `class {cls.__name__}(RootModel[{parameters_str}]): ...`.'
                        )
                    else:
                        combined_parameters = parent_parameters + missing_parameters
                        parameters_str = ', '.join([str(x) for x in combined_parameters])
                        generic_type_label = f'typing.Generic[{parameters_str}]'
                        error_message = (
                            f'All parameters must be present on typing.Generic;'
                            f' you should inherit from {generic_type_label}.'
                        )
                        if Generic not in bases:  # pragma: no cover
                            # We raise an error here not because it is desirable, but because some cases are mishandled.
                            # It would be nice to remove this error and still have things behave as expected, it's just
                            # challenging because we are using a custom `__class_getitem__` to parametrize generic models,
                            # and not returning a typing._GenericAlias from it.
                            bases_str = ', '.join([x.__name__ for x in bases] + [generic_type_label])
                            error_message += (
                                f' Note: `typing.Generic` must go last: `class {cls.__name__}({bases_str}): ...`)'
                            )
                    raise TypeError(error_message)
    
                cls.__pydantic_generic_metadata__ = {
                    'origin': None,
                    'args': (),
                    'parameters': parameters,
                }
    
            cls.__pydantic_complete__ = False  # Ensure this specific class gets completed
    
            # preserve `__set_name__` protocol defined in https://peps.python.org/pep-0487
            # for attributes not in `new_namespace` (e.g. private attributes)
            for name, obj in private_attributes.items():
                obj.__set_name__(cls, name)
    
            if __pydantic_reset_parent_namespace__:
                cls.__pydantic_parent_namespace__ = build_lenient_weakvaluedict(parent_frame_namespace())
            parent_namespace: dict[str, Any] | None = getattr(cls, '__pydantic_parent_namespace__', None)
            if isinstance(parent_namespace, dict):
                parent_namespace = unpack_lenient_weakvaluedict(parent_namespace)
    
            ns_resolver = NsResolver(parent_namespace=parent_namespace)
    
            set_model_fields(cls, config_wrapper=config_wrapper, ns_resolver=ns_resolver)
    
            # This is also set in `complete_model_class()`, after schema gen because they are recreated.
            # We set them here as well for backwards compatibility:
            cls.__pydantic_computed_fields__ = {
                k: v.info for k, v in cls.__pydantic_decorators__.computed_fields.items()
            }
    
            if config_wrapper.defer_build:
                set_model_mocks(cls)
            else:
                # Any operation that requires accessing the field infos instances should be put inside
                # `complete_model_class()`:
>               complete_model_class(
                    cls,
                    config_wrapper,
                    ns_resolver,
                    raise_errors=False,
                    create_model_module=_create_model_module,
                )

venv/lib/python3.13/site-packages/pydantic/_internal/_model_construction.py:255: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'src.config.GoogleSheetsConfig'>, config_wrapper = ConfigWrapper()
ns_resolver = <pydantic._internal._namespace_utils.NsResolver object at 0x10699dcd0>

    def complete_model_class(
        cls: type[BaseModel],
        config_wrapper: ConfigWrapper,
        ns_resolver: NsResolver,
        *,
        raise_errors: bool = True,
        call_on_complete_hook: bool = True,
        create_model_module: str | None = None,
    ) -> bool:
        """Finish building a model class.
    
        This logic must be called after class has been created since validation functions must be bound
        and `get_type_hints` requires a class object.
    
        Args:
            cls: BaseModel or dataclass.
            config_wrapper: The config wrapper instance.
            ns_resolver: The namespace resolver instance to use during schema building.
            raise_errors: Whether to raise errors.
            call_on_complete_hook: Whether to call the `__pydantic_on_complete__` hook.
            create_model_module: The module of the class to be created, if created by `create_model`.
    
        Returns:
            `True` if the model is successfully completed, else `False`.
    
        Raises:
            PydanticUndefinedAnnotation: If `PydanticUndefinedAnnotation` occurs in`__get_pydantic_core_schema__`
                and `raise_errors=True`.
        """
        typevars_map = get_model_typevars_map(cls)
    
        if not cls.__pydantic_fields_complete__:
            # Note: when coming from `ModelMetaclass.__new__()`, this results in fields being built twice.
            # We do so a second time here so that we can get the `NameError` for the specific undefined annotation.
            # Alternatively, we could let `GenerateSchema()` raise the error, but there are cases where incomplete
            # fields are inherited in `collect_model_fields()` and can actually have their annotation resolved in the
            # generate schema process. As we want to avoid having `__pydantic_fields_complete__` set to `False`
            # when `__pydantic_complete__` is `True`, we rebuild here:
            try:
                cls.__pydantic_fields__ = rebuild_model_fields(
                    cls,
                    config_wrapper=config_wrapper,
                    ns_resolver=ns_resolver,
                    typevars_map=typevars_map,
                )
            except NameError as e:
                exc = PydanticUndefinedAnnotation.from_name_error(e)
                set_model_mocks(cls, f'`{exc.name}`')
                if raise_errors:
                    raise exc from e
    
            if not raise_errors and not cls.__pydantic_fields_complete__:
                # No need to continue with schema gen, it is guaranteed to fail
                return False
    
            assert cls.__pydantic_fields_complete__
    
        gen_schema = GenerateSchema(
            config_wrapper,
            ns_resolver,
            typevars_map,
        )
    
        try:
>           schema = gen_schema.generate_schema(cls)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_model_construction.py:648: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x1069a7600>
obj = <class 'src.config.GoogleSheetsConfig'>

    def generate_schema(
        self,
        obj: Any,
    ) -> core_schema.CoreSchema:
        """Generate core schema.
    
        Args:
            obj: The object to generate core schema for.
    
        Returns:
            The generated core schema.
    
        Raises:
            PydanticUndefinedAnnotation:
                If it is not possible to evaluate forward reference.
            PydanticSchemaGenerationError:
                If it is not possible to generate pydantic-core schema.
            TypeError:
                - If `alias_generator` returns a disallowed type (must be str, AliasPath or AliasChoices).
                - If V1 style validator with `each_item=True` applied on a wrong field.
            PydanticUserError:
                - If `typing.TypedDict` is used instead of `typing_extensions.TypedDict` on Python < 3.12.
                - If `__modify_schema__` method is used instead of `__get_pydantic_json_schema__`.
        """
        schema = self._generate_schema_from_get_schema_method(obj, obj)
    
        if schema is None:
>           schema = self._generate_schema_inner(obj)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x1069a7600>
obj = <class 'src.config.GoogleSheetsConfig'>

    def _generate_schema_inner(self, obj: Any) -> core_schema.CoreSchema:
        if typing_objects.is_self(obj):
            obj = self._resolve_self_type(obj)
    
        if typing_objects.is_annotated(get_origin(obj)):
            return self._annotated_schema(obj)
    
        if isinstance(obj, dict):
            # we assume this is already a valid schema
            return obj  # type: ignore[return-value]
    
        if isinstance(obj, str):
            obj = ForwardRef(obj)
    
        if isinstance(obj, ForwardRef):
            return self.generate_schema(self._resolve_forward_ref(obj))
    
        BaseModel = import_cached_base_model()
    
        if lenient_issubclass(obj, BaseModel):
            with self.model_type_stack.push(obj):
>               return self._model_schema(obj)
                       ^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1023: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x1069a7600>
cls = <class 'src.config.GoogleSheetsConfig'>

    def _model_schema(self, cls: type[BaseModel]) -> core_schema.CoreSchema:
        """Generate schema for a Pydantic model."""
        BaseModel_ = import_cached_base_model()
    
        with self.defs.get_schema_or_ref(cls) as (model_ref, maybe_schema):
            if maybe_schema is not None:
                return maybe_schema
    
            schema = cls.__dict__.get('__pydantic_core_schema__')
            if schema is not None and not isinstance(schema, MockCoreSchema):
                if schema['type'] == 'definitions':
                    schema = self.defs.unpack_definitions(schema)
                ref = get_ref(schema)
                if ref:
                    return self.defs.create_definition_reference_schema(schema)
                else:
                    return schema
    
            config_wrapper = ConfigWrapper(cls.model_config, check=False)
    
            with self._config_wrapper_stack.push(config_wrapper), self._ns_resolver.push(cls):
                core_config = self._config_wrapper.core_config(title=cls.__name__)
    
                if cls.__pydantic_fields_complete__ or cls is BaseModel_:
                    fields = getattr(cls, '__pydantic_fields__', {})
                else:
                    if '__pydantic_fields__' not in cls.__dict__:
                        # This happens when we have a loop in the schema generation:
                        # class Base[T](BaseModel):
                        #     t: T
                        #
                        # class Other(BaseModel):
                        #     b: 'Base[Other]'
                        # When we build fields for `Other`, we evaluate the forward annotation.
                        # At this point, `Other` doesn't have the model fields set. We create
                        # `Base[Other]`; model fields are successfully built, and we try to generate
                        # a schema for `t: Other`. As `Other.__pydantic_fields__` aren't set, we abort.
                        raise PydanticUndefinedAnnotation(
                            name=cls.__name__,
                            message=f'Class {cls.__name__!r} is not defined',
                        )
                    try:
                        fields = rebuild_model_fields(
                            cls,
                            config_wrapper=self._config_wrapper,
                            ns_resolver=self._ns_resolver,
                            typevars_map=self._typevars_map or {},
                        )
                    except NameError as e:
                        raise PydanticUndefinedAnnotation.from_name_error(e) from e
    
                decorators = cls.__pydantic_decorators__
                computed_fields = decorators.computed_fields
                check_decorator_fields_exist(
                    chain(
                        decorators.field_validators.values(),
                        decorators.field_serializers.values(),
                        decorators.validators.values(),
                    ),
                    {*fields.keys(), *computed_fields.keys()},
                )
    
                model_validators = decorators.model_validators.values()
    
                extras_schema = None
                extras_keys_schema = None
                if core_config.get('extra_fields_behavior') == 'allow':
                    assert cls.__mro__[0] is cls
                    assert cls.__mro__[-1] is object
                    for candidate_cls in cls.__mro__[:-1]:
                        extras_annotation = getattr(candidate_cls, '__annotations__', {}).get(
                            '__pydantic_extra__', None
                        )
                        if extras_annotation is not None:
                            if isinstance(extras_annotation, str):
                                extras_annotation = _typing_extra.eval_type_backport(
                                    _typing_extra._make_forward_ref(
                                        extras_annotation, is_argument=False, is_class=True
                                    ),
                                    *self._types_namespace,
                                )
                            tp = get_origin(extras_annotation)
                            if tp not in DICT_TYPES:
                                raise PydanticSchemaGenerationError(
                                    'The type annotation for `__pydantic_extra__` must be `dict[str, ...]`'
                                )
                            extra_keys_type, extra_items_type = self._get_args_resolving_forward_refs(
                                extras_annotation,
                                required=True,
                            )
                            if extra_keys_type is not str:
                                extras_keys_schema = self.generate_schema(extra_keys_type)
                            if not typing_objects.is_any(extra_items_type):
                                extras_schema = self.generate_schema(extra_items_type)
                            if extras_keys_schema is not None or extras_schema is not None:
                                break
    
                generic_origin: type[BaseModel] | None = getattr(cls, '__pydantic_generic_metadata__', {}).get('origin')
    
                if cls.__pydantic_root_model__:
                    # FIXME: should the common field metadata be used here?
                    inner_schema, _ = self._common_field_schema('root', fields['root'], decorators)
                    inner_schema = apply_model_validators(inner_schema, model_validators, 'inner')
                    model_schema = core_schema.model_schema(
                        cls,
                        inner_schema,
                        generic_origin=generic_origin,
                        custom_init=getattr(cls, '__pydantic_custom_init__', None),
                        root_model=True,
                        post_init=getattr(cls, '__pydantic_post_init__', None),
                        config=core_config,
                        ref=model_ref,
                    )
                else:
                    fields_schema: core_schema.CoreSchema = core_schema.model_fields_schema(
>                       {k: self._generate_md_field_schema(k, v, decorators) for k, v in fields.items()},
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                        computed_fields=[
                            self._computed_field_schema(d, decorators.field_serializers)
                            for d in computed_fields.values()
                        ],
                        extras_schema=extras_schema,
                        extras_keys_schema=extras_keys_schema,
                        model_name=cls.__name__,
                    )

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:856: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x1069a7600>
name = 'credentials'
field_info = FieldInfo(annotation=Union[ServiceAccountCredentials, OAuth2Credentials], required=True, description='Authentication credentials', discriminator='auth_type')
decorators = DecoratorInfos(validators={}, field_validators={'extract_spreadsheet_id': Decorator(cls_ref='src.config.GoogleSheetsCo...cUndefined))}, root_validators={}, field_serializers={}, model_serializers={}, model_validators={}, computed_fields={})

    def _generate_md_field_schema(
        self,
        name: str,
        field_info: FieldInfo,
        decorators: DecoratorInfos,
    ) -> core_schema.ModelField:
        """Prepare a ModelField to represent a model field."""
>       schema, metadata = self._common_field_schema(name, field_info, decorators)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x1069a7600>
name = 'credentials'
field_info = FieldInfo(annotation=Union[ServiceAccountCredentials, OAuth2Credentials], required=True, description='Authentication credentials', discriminator='auth_type')
decorators = DecoratorInfos(validators={}, field_validators={'extract_spreadsheet_id': Decorator(cls_ref='src.config.GoogleSheetsCo...cUndefined))}, root_validators={}, field_serializers={}, model_serializers={}, model_validators={}, computed_fields={})

    def _common_field_schema(  # C901
        self, name: str, field_info: FieldInfo, decorators: DecoratorInfos
    ) -> tuple[CoreSchema, dict[str, Any]]:
        source_type, annotations = field_info.annotation, field_info.metadata
    
        def set_discriminator(schema: CoreSchema) -> CoreSchema:
            schema = self._apply_discriminator_to_union(schema, field_info.discriminator)
            return schema
    
        # Convert `@field_validator` decorators to `Before/After/Plain/WrapValidator` instances:
        validators_from_decorators = [
            _mode_to_validator[decorator.info.mode]._from_decorator(decorator)
            for decorator in filter_field_decorator_info_by_field(decorators.field_validators.values(), name)
        ]
    
        with self.field_name_stack.push(name):
            if field_info.discriminator is not None:
>               schema = self._apply_annotations(
                    source_type, annotations + validators_from_decorators, transform_inner_schema=set_discriminator
                )

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1278: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x1069a7600>
source_type = typing.Union[src.config.ServiceAccountCredentials, src.config.OAuth2Credentials]
annotations = []
transform_inner_schema = <function GenerateSchema._common_field_schema.<locals>.set_discriminator at 0x106b70540>
check_unsupported_field_info_attributes = True

    def _apply_annotations(
        self,
        source_type: Any,
        annotations: list[Any],
        transform_inner_schema: Callable[[CoreSchema], CoreSchema] = lambda x: x,
        check_unsupported_field_info_attributes: bool = True,
    ) -> CoreSchema:
        """Apply arguments from `Annotated` or from `FieldInfo` to a schema.
    
        This gets called by `GenerateSchema._annotated_schema` but differs from it in that it does
        not expect `source_type` to be an `Annotated` object, it expects it to be  the first argument of that
        (in other words, `GenerateSchema._annotated_schema` just unpacks `Annotated`, this process it).
        """
        annotations = list(_known_annotated_metadata.expand_grouped_metadata(annotations))
    
        pydantic_js_annotation_functions: list[GetJsonSchemaFunction] = []
    
        def inner_handler(obj: Any) -> CoreSchema:
            schema = self._generate_schema_from_get_schema_method(obj, source_type)
    
            if schema is None:
                schema = self._generate_schema_inner(obj)
    
            metadata_js_function = _extract_get_pydantic_json_schema(obj)
            if metadata_js_function is not None:
                metadata_schema = resolve_original_schema(schema, self.defs)
                if metadata_schema is not None:
                    self._add_js_function(metadata_schema, metadata_js_function)
            return transform_inner_schema(schema)
    
        get_inner_schema = CallbackGetCoreSchemaHandler(inner_handler, self)
    
        for annotation in annotations:
            if annotation is None:
                continue
            get_inner_schema = self._get_wrapped_inner_schema(
                get_inner_schema,
                annotation,
                pydantic_js_annotation_functions,
                check_unsupported_field_info_attributes=check_unsupported_field_info_attributes,
            )
    
>       schema = get_inner_schema(source_type)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2227: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._schema_generation_shared.CallbackGetCoreSchemaHandler object at 0x103ecb1d0>
source_type = typing.Union[src.config.ServiceAccountCredentials, src.config.OAuth2Credentials]

    def __call__(self, source_type: Any, /) -> core_schema.CoreSchema:
>       schema = self._handler(source_type)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_schema_generation_shared.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = typing.Union[src.config.ServiceAccountCredentials, src.config.OAuth2Credentials]

    def inner_handler(obj: Any) -> CoreSchema:
        schema = self._generate_schema_from_get_schema_method(obj, source_type)
    
        if schema is None:
            schema = self._generate_schema_inner(obj)
    
        metadata_js_function = _extract_get_pydantic_json_schema(obj)
        if metadata_js_function is not None:
            metadata_schema = resolve_original_schema(schema, self.defs)
            if metadata_schema is not None:
                self._add_js_function(metadata_schema, metadata_js_function)
>       return transform_inner_schema(schema)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2213: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

schema = {'choices': [{'schema_ref': 'src.config.ServiceAccountCredentials:4416627280', 'type': 'definition-ref'}, {'schema_ref': 'src.config.OAuth2Credentials:4415600576', 'type': 'definition-ref'}], 'type': 'union'}

    def set_discriminator(schema: CoreSchema) -> CoreSchema:
>       schema = self._apply_discriminator_to_union(schema, field_info.discriminator)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:1267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._generate_schema.GenerateSchema object at 0x1069a7600>
schema = {'choices': [{'schema_ref': 'src.config.ServiceAccountCredentials:4416627280', 'type': 'definition-ref'}, {'schema_ref': 'src.config.OAuth2Credentials:4415600576', 'type': 'definition-ref'}], 'type': 'union'}
discriminator = 'auth_type'

    def _apply_discriminator_to_union(
        self, schema: CoreSchema, discriminator: str | Discriminator | None
    ) -> CoreSchema:
        if discriminator is None:
            return schema
        try:
>           return _discriminated_union.apply_discriminator(
                schema,
                discriminator,
                self.defs._definitions,
            )

venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:675: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

schema = {'choices': [{'schema_ref': 'src.config.ServiceAccountCredentials:4416627280', 'type': 'definition-ref'}, {'schema_ref': 'src.config.OAuth2Credentials:4415600576', 'type': 'definition-ref'}], 'type': 'union'}
discriminator = 'auth_type'
definitions = {'src.config.OAuth2Credentials:4415600576': {'cls': <class 'src.config.OAuth2Credentials'>, 'config': {'title': 'OAuth...Credentials'>, 'config': {'title': 'ServiceAccountCredentials'}, 'custom_init': False, 'root_model': False, ...}, ...}}

    def apply_discriminator(
        schema: core_schema.CoreSchema,
        discriminator: str | Discriminator,
        definitions: dict[str, core_schema.CoreSchema] | None = None,
    ) -> core_schema.CoreSchema:
        """Applies the discriminator and returns a new core schema.
    
        Args:
            schema: The input schema.
            discriminator: The name of the field which will serve as the discriminator.
            definitions: A mapping of schema ref to schema.
    
        Returns:
            The new core schema.
    
        Raises:
            TypeError:
                - If `discriminator` is used with invalid union variant.
                - If `discriminator` is used with `Union` type with one variant.
                - If `discriminator` value mapped to multiple choices.
            MissingDefinitionForUnionRef:
                If the definition for ref is missing.
            PydanticUserError:
                - If a model in union doesn't have a discriminator field.
                - If discriminator field has a non-string alias.
                - If discriminator fields have different aliases.
                - If discriminator field not of type `Literal`.
        """
        from ..types import Discriminator
    
        if isinstance(discriminator, Discriminator):
            if isinstance(discriminator.discriminator, str):
                discriminator = discriminator.discriminator
            else:
                return discriminator._convert_schema(schema)
    
>       return _ApplyInferredDiscriminator(discriminator, definitions or {}).apply(schema)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10693f950>
schema = {'choices': [{'schema_ref': 'src.config.ServiceAccountCredentials:4416627280', 'type': 'definition-ref'}, {'schema_ref': 'src.config.OAuth2Credentials:4415600576', 'type': 'definition-ref'}], 'type': 'union'}

    def apply(self, schema: core_schema.CoreSchema) -> core_schema.CoreSchema:
        """Return a new CoreSchema based on `schema` that uses a tagged-union with the discriminator provided
        to this class.
    
        Args:
            schema: The input schema.
    
        Returns:
            The new core schema.
    
        Raises:
            TypeError:
                - If `discriminator` is used with invalid union variant.
                - If `discriminator` is used with `Union` type with one variant.
                - If `discriminator` value mapped to multiple choices.
            ValueError:
                If the definition for ref is missing.
            PydanticUserError:
                - If a model in union doesn't have a discriminator field.
                - If discriminator field has a non-string alias.
                - If discriminator fields have different aliases.
                - If discriminator field not of type `Literal`.
        """
        assert not self._used
>       schema = self._apply_to_root(schema)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:164: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10693f950>
schema = {'choices': [{'schema_ref': 'src.config.ServiceAccountCredentials:4416627280', 'type': 'definition-ref'}, {'schema_ref': 'src.config.OAuth2Credentials:4415600576', 'type': 'definition-ref'}], 'type': 'union'}

    def _apply_to_root(self, schema: core_schema.CoreSchema) -> core_schema.CoreSchema:
        """This method handles the outer-most stage of recursion over the input schema:
        unwrapping nullable or definitions schemas, and calling the `_handle_choice`
        method iteratively on the choices extracted (recursively) from the possibly-wrapped union.
        """
        if schema['type'] == 'nullable':
            self._is_nullable = True
            wrapped = self._apply_to_root(schema['schema'])
            nullable_wrapper = schema.copy()
            nullable_wrapper['schema'] = wrapped
            return nullable_wrapper
    
        if schema['type'] == 'definitions':
            wrapped = self._apply_to_root(schema['schema'])
            definitions_wrapper = schema.copy()
            definitions_wrapper['schema'] = wrapped
            return definitions_wrapper
    
        if schema['type'] != 'union':
            # If the schema is not a union, it probably means it just had a single member and
            # was flattened by pydantic_core.
            # However, it still may make sense to apply the discriminator to this schema,
            # as a way to get discriminated-union-style error messages, so we allow this here.
            schema = core_schema.union_schema([schema])
    
        # Reverse the choices list before extending the stack so that they get handled in the order they occur
        choices_schemas = [v[0] if isinstance(v, tuple) else v for v in schema['choices'][::-1]]
        self._choices_to_handle.extend(choices_schemas)
        while self._choices_to_handle:
            choice = self._choices_to_handle.pop()
>           self._handle_choice(choice)

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10693f950>
choice = {'schema_ref': 'src.config.ServiceAccountCredentials:4416627280', 'type': 'definition-ref'}

    def _handle_choice(self, choice: core_schema.CoreSchema) -> None:
        """This method handles the "middle" stage of recursion over the input schema.
        Specifically, it is responsible for handling each choice of the outermost union
        (and any "coalesced" choices obtained from inner unions).
    
        Here, "handling" entails:
        * Coalescing nested unions and compatible tagged-unions
        * Tracking the presence of 'none' and 'nullable' schemas occurring as choices
        * Validating that each allowed discriminator value maps to a unique choice
        * Updating the _tagged_union_choices mapping that will ultimately be used to build the TaggedUnionSchema.
        """
        if choice['type'] == 'definition-ref':
            if choice['schema_ref'] not in self.definitions:
                raise MissingDefinitionForUnionRef(choice['schema_ref'])
    
        if choice['type'] == 'none':
            self._should_be_nullable = True
        elif choice['type'] == 'definitions':
            self._handle_choice(choice['schema'])
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            self._handle_choice(choice['schema'])  # unwrap the nullable schema
        elif choice['type'] == 'union':
            # Reverse the choices list before extending the stack so that they get handled in the order they occur
            choices_schemas = [v[0] if isinstance(v, tuple) else v for v in choice['choices'][::-1]]
            self._choices_to_handle.extend(choices_schemas)
        elif choice['type'] not in {
            'model',
            'typed-dict',
            'tagged-union',
            'lax-or-strict',
            'dataclass',
            'dataclass-args',
            'definition-ref',
        } and not _core_utils.is_function_with_inner_schema(choice):
            # We should eventually handle 'definition-ref' as well
            err_str = f'The core schema type {choice["type"]!r} is not a valid discriminated union variant.'
            if choice['type'] == 'list':
                err_str += (
                    ' If you are making use of a list of union types, make sure the discriminator is applied to the '
                    'union type and not the list (e.g. `list[Annotated[<T> | <U>, Field(discriminator=...)]]`).'
                )
            raise TypeError(err_str)
        else:
            if choice['type'] == 'tagged-union' and self._is_discriminator_shared(choice):
                # In this case, this inner tagged-union is compatible with the outer tagged-union,
                # and its choices can be coalesced into the outer TaggedUnionSchema.
                subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
                # Reverse the choices list before extending the stack so that they get handled in the order they occur
                self._choices_to_handle.extend(subchoices[::-1])
                return
    
>           inferred_discriminator_values = self._infer_discriminator_values_for_choice(choice, source_name=None)
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:278: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10693f950>
choice = {'schema_ref': 'src.config.ServiceAccountCredentials:4416627280', 'type': 'definition-ref'}
source_name = None

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif choice['type'] == 'lax-or-strict':
            return sorted(
                set(
                    self._infer_discriminator_values_for_choice(choice['lax_schema'], source_name=None)
                    + self._infer_discriminator_values_for_choice(choice['strict_schema'], source_name=None)
                )
            )
    
        elif choice['type'] == 'tagged-union':
            values: list[str | int] = []
            # Ignore str/int "choices" since these are just references to other choices
            subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
            for subchoice in subchoices:
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'union':
            values = []
            for subchoice in choice['choices']:
                subchoice_schema = subchoice[0] if isinstance(subchoice, tuple) else subchoice
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice_schema, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=None)
    
        elif choice['type'] == 'model':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'dataclass':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'model-fields':
            return self._infer_discriminator_values_for_model_choice(choice, source_name=source_name)
    
        elif choice['type'] == 'dataclass-args':
            return self._infer_discriminator_values_for_dataclass_choice(choice, source_name=source_name)
    
        elif choice['type'] == 'typed-dict':
            return self._infer_discriminator_values_for_typed_dict_choice(choice, source_name=source_name)
    
        elif choice['type'] == 'definition-ref':
            schema_ref = choice['schema_ref']
            if schema_ref not in self.definitions:
                raise MissingDefinitionForUnionRef(schema_ref)
>           return self._infer_discriminator_values_for_choice(self.definitions[schema_ref], source_name=source_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10693f950>
choice = {'function': {'function': <function ServiceAccountCredentials.validate_credentials_source at 0x106c11940>, 'type': 'no...tCredentials'>, 'config': {'title': 'ServiceAccountCredentials'}, 'custom_init': False, 'root_model': False, ...}, ...}
source_name = None

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
>           return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:304: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10693f950>
choice = {'cls': <class 'src.config.ServiceAccountCredentials'>, 'config': {'title': 'ServiceAccountCredentials'}, 'custom_init': False, 'root_model': False, ...}
source_name = None

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif choice['type'] == 'lax-or-strict':
            return sorted(
                set(
                    self._infer_discriminator_values_for_choice(choice['lax_schema'], source_name=None)
                    + self._infer_discriminator_values_for_choice(choice['strict_schema'], source_name=None)
                )
            )
    
        elif choice['type'] == 'tagged-union':
            values: list[str | int] = []
            # Ignore str/int "choices" since these are just references to other choices
            subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
            for subchoice in subchoices:
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'union':
            values = []
            for subchoice in choice['choices']:
                subchoice_schema = subchoice[0] if isinstance(subchoice, tuple) else subchoice
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice_schema, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=None)
    
        elif choice['type'] == 'model':
>           return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10693f950>
choice = {'computed_fields': [], 'fields': {'auth_type': {'metadata': {'pydantic_js_updates': {'description': 'Authentication t...fore'}, 'type': 'default'}, 'type': 'model-field'}}, 'model_name': 'ServiceAccountCredentials', 'type': 'model-fields'}
source_name = 'ServiceAccountCredentials'

    def _infer_discriminator_values_for_choice(  # noqa C901
        self, choice: core_schema.CoreSchema, source_name: str | None
    ) -> list[str | int]:
        """This function recurses over `choice`, extracting all discriminator values that should map to this choice.
    
        `model_name` is accepted for the purpose of producing useful error messages.
        """
        if choice['type'] == 'definitions':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif _core_utils.is_function_with_inner_schema(choice):
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=source_name)
    
        elif choice['type'] == 'lax-or-strict':
            return sorted(
                set(
                    self._infer_discriminator_values_for_choice(choice['lax_schema'], source_name=None)
                    + self._infer_discriminator_values_for_choice(choice['strict_schema'], source_name=None)
                )
            )
    
        elif choice['type'] == 'tagged-union':
            values: list[str | int] = []
            # Ignore str/int "choices" since these are just references to other choices
            subchoices = [x for x in choice['choices'].values() if not isinstance(x, (str, int))]
            for subchoice in subchoices:
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'union':
            values = []
            for subchoice in choice['choices']:
                subchoice_schema = subchoice[0] if isinstance(subchoice, tuple) else subchoice
                subchoice_values = self._infer_discriminator_values_for_choice(subchoice_schema, source_name=None)
                values.extend(subchoice_values)
            return values
    
        elif choice['type'] == 'nullable':
            self._should_be_nullable = True
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=None)
    
        elif choice['type'] == 'model':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'dataclass':
            return self._infer_discriminator_values_for_choice(choice['schema'], source_name=choice['cls'].__name__)
    
        elif choice['type'] == 'model-fields':
>           return self._infer_discriminator_values_for_model_choice(choice, source_name=source_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:342: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10693f950>
choice = {'computed_fields': [], 'fields': {'auth_type': {'metadata': {'pydantic_js_updates': {'description': 'Authentication t...fore'}, 'type': 'default'}, 'type': 'model-field'}}, 'model_name': 'ServiceAccountCredentials', 'type': 'model-fields'}
source_name = 'ServiceAccountCredentials'

    def _infer_discriminator_values_for_model_choice(
        self, choice: core_schema.ModelFieldsSchema, source_name: str | None = None
    ) -> list[str | int]:
        source = 'ModelFields' if source_name is None else f'Model {source_name!r}'
        field = choice['fields'].get(self.discriminator)
        if field is None:
            raise PydanticUserError(
                f'{source} needs a discriminator field for key {self.discriminator!r}', code='discriminator-no-field'
            )
>       return self._infer_discriminator_values_for_field(field, source)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10693f950>
field = {'metadata': {'pydantic_js_updates': {'description': 'Authentication type identifier'}}, 'schema': {'default': <AuthTy...son_schema at 0x106c10ae0>]}, 'ref': 'src.config.AuthType:4416623936', ...}, 'type': 'default'}, 'type': 'model-field'}
source = "Model 'ServiceAccountCredentials'"

    def _infer_discriminator_values_for_field(self, field: CoreSchemaField, source: str) -> list[str | int]:
        if field['type'] == 'computed-field':
            # This should never occur as a discriminator, as it is only relevant to serialization
            return []
        alias = field.get('validation_alias', self.discriminator)
        if not isinstance(alias, str):
            raise PydanticUserError(
                f'Alias {alias!r} is not supported in a discriminated union', code='discriminator-alias-type'
            )
        if self._discriminator_alias is None:
            self._discriminator_alias = alias
        elif self._discriminator_alias != alias:
            raise PydanticUserError(
                f'Aliases for discriminator {self.discriminator!r} must be the same '
                f'(got {alias}, {self._discriminator_alias})',
                code='discriminator-alias',
            )
>       return self._infer_discriminator_values_for_inner_schema(field['schema'], source)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:419: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10693f950>
schema = {'default': <AuthType.SERVICE_ACCOUNT: 'service_account'>, 'schema': {'cls': <enum 'AuthType'>, 'members': [<AuthType....um_schema.<locals>.get_json_schema at 0x106c10ae0>]}, 'ref': 'src.config.AuthType:4416623936', ...}, 'type': 'default'}
source = "Model 'ServiceAccountCredentials'"

    def _infer_discriminator_values_for_inner_schema(
        self, schema: core_schema.CoreSchema, source: str
    ) -> list[str | int]:
        """When inferring discriminator values for a field, we typically extract the expected values from a literal
        schema. This function does that, but also handles nested unions and defaults.
        """
        if schema['type'] == 'literal':
            return schema['expected']
    
        elif schema['type'] == 'union':
            # Generally when multiple values are allowed they should be placed in a single `Literal`, but
            # we add this case to handle the situation where a field is annotated as a `Union` of `Literal`s.
            # For example, this lets us handle `Union[Literal['key'], Union[Literal['Key'], Literal['KEY']]]`
            values: list[Any] = []
            for choice in schema['choices']:
                choice_schema = choice[0] if isinstance(choice, tuple) else choice
                choice_values = self._infer_discriminator_values_for_inner_schema(choice_schema, source)
                values.extend(choice_values)
            return values
    
        elif schema['type'] == 'default':
            # This will happen if the field has a default value; we ignore it while extracting the discriminator values
>           return self._infer_discriminator_values_for_inner_schema(schema['schema'], source)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:443: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pydantic._internal._discriminated_union._ApplyInferredDiscriminator object at 0x10693f950>
schema = {'cls': <enum 'AuthType'>, 'members': [<AuthType.SERVICE_ACCOUNT: 'service_account'>, <AuthType.OAUTH2: 'oauth2'>], 'm...n GenerateSchema._enum_schema.<locals>.get_json_schema at 0x106c10ae0>]}, 'ref': 'src.config.AuthType:4416623936', ...}
source = "Model 'ServiceAccountCredentials'"

    def _infer_discriminator_values_for_inner_schema(
        self, schema: core_schema.CoreSchema, source: str
    ) -> list[str | int]:
        """When inferring discriminator values for a field, we typically extract the expected values from a literal
        schema. This function does that, but also handles nested unions and defaults.
        """
        if schema['type'] == 'literal':
            return schema['expected']
    
        elif schema['type'] == 'union':
            # Generally when multiple values are allowed they should be placed in a single `Literal`, but
            # we add this case to handle the situation where a field is annotated as a `Union` of `Literal`s.
            # For example, this lets us handle `Union[Literal['key'], Union[Literal['Key'], Literal['KEY']]]`
            values: list[Any] = []
            for choice in schema['choices']:
                choice_schema = choice[0] if isinstance(choice, tuple) else choice
                choice_values = self._infer_discriminator_values_for_inner_schema(choice_schema, source)
                values.extend(choice_values)
            return values
    
        elif schema['type'] == 'default':
            # This will happen if the field has a default value; we ignore it while extracting the discriminator values
            return self._infer_discriminator_values_for_inner_schema(schema['schema'], source)
    
        elif schema['type'] == 'function-after':
            # After validators don't affect the discriminator values
            return self._infer_discriminator_values_for_inner_schema(schema['schema'], source)
    
        elif schema['type'] in {'function-before', 'function-wrap', 'function-plain'}:
            validator_type = repr(schema['type'].split('-')[1])
            raise PydanticUserError(
                f'Cannot use a mode={validator_type} validator in the'
                f' discriminator field {self.discriminator!r} of {source}',
                code='discriminator-validator',
            )
    
        else:
>           raise PydanticUserError(
                f'{source} needs field {self.discriminator!r} to be of type `Literal`',
                code='discriminator-needs-literal',
            )
E           pydantic.errors.PydanticUserError: Model 'ServiceAccountCredentials' needs field 'auth_type' to be of type `Literal`
E           
E           For further information visit https://errors.pydantic.dev/2.12/u/discriminator-needs-literal

venv/lib/python3.13/site-packages/pydantic/_internal/_discriminated_union.py:458: PydanticUserError
=========================== short test summary info ============================
ERROR tests/test_config.py - pydantic.errors.PydanticUserError: Model 'ServiceAccountCredentials' needs field 'auth_type' to be of type `Literal`

For further information visit https://errors.pydantic.dev/2.12/u/discriminator-needs-literal
ERROR tests/test_connection.py - pydantic.errors.PydanticUserError: Model 'ServiceAccountCredentials' needs field 'auth_type' to be of type `Literal`

For further information visit https://errors.pydantic.dev/2.12/u/discriminator-needs-literal
ERROR tests/test_discovery.py - pydantic.errors.PydanticUserError: Model 'ServiceAccountCredentials' needs field 'auth_type' to be of type `Literal`

For further information visit https://errors.pydantic.dev/2.12/u/discriminator-needs-literal
ERROR tests/test_read.py - pydantic.errors.PydanticUserError: Model 'ServiceAccountCredentials' needs field 'auth_type' to be of type `Literal`

For further information visit https://errors.pydantic.dev/2.12/u/discriminator-needs-literal
!!!!!!!!!!!!!!!!!!! Interrupted: 4 errors during collection !!!!!!!!!!!!!!!!!!!!
============================== 4 errors in 0.68s ===============================
